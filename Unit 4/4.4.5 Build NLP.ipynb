{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from collections import Counter\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "from sklearn import ensemble\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to clean text.\n",
    "def text_cleaner(text):\n",
    "    \n",
    "    # Visual inspection shows spaCy does not recognize the double dash '--'.\n",
    "    # Better get rid of it now!\n",
    "    text = re.sub(r'--',' ',text)\n",
    "    \n",
    "    # Get rid of headings in square brackets.\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    \n",
    "    # Get rid of chapter titles.\n",
    "    text = re.sub(r'Chapter \\d+','',text)\n",
    "    text = re.sub(r'CHAPTER \\d+', '', text)\n",
    "    text = re.sub(\"\\\\n\\\\n.*?\\\\n\\\\n\", '', text)\n",
    "  \n",
    "    # Get rid of extra whitespace.\n",
    "    text = ' '.join(text.split())\n",
    "\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load documents\n",
    "ball = gutenberg.raw('chesterton-ball.txt')\n",
    "brown = gutenberg.raw('chesterton-brown.txt')\n",
    "thursday = gutenberg.raw('chesterton-thursday.txt')\n",
    "\n",
    "# clean texts\n",
    "ball = text_cleaner(ball)\n",
    "brown = text_cleaner(brown)\n",
    "thursday = text_cleaner(thursday)\n",
    "\n",
    "# run spacy and analyze the documents\n",
    "nlp = spacy.load('en')\n",
    "ball_doc = nlp(ball)\n",
    "brown_doc = nlp(brown)\n",
    "thursday_doc = nlp(thursday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_sents = []\n",
    "ball_sents = []\n",
    "thursday_sents = []\n",
    "for sentence in brown_doc.sents:\n",
    "    brown_sents.append(sentence)\n",
    "for sentence in ball_doc.sents:\n",
    "    ball_sents.append(sentence)\n",
    "for sentence in thursday_doc.sents:\n",
    "    thursday_sents.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of\n",
      "Brown sentences: 3534\n",
      "Ball sentences: 4272\n",
      "Thursday sentences: 3053\n"
     ]
    }
   ],
   "source": [
    "print('Length of\\nBrown sentences: {}\\nBall sentences: {}\\nThursday sentences: {}'.format(len(brown_sents), len(ball_sents), len(thursday_sents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_sents = brown_sents[:2000]\n",
    "ball_sents = ball_sents[:2000]\n",
    "thursday_sents = thursday_sents[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(The, flying, ship, of, Professor, Lucifer, sa...</td>\n",
       "      <td>Ball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(That, it, was, far, above, the, earth, was, n...</td>\n",
       "      <td>Ball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(The, professor, had, himself, invented, the, ...</td>\n",
       "      <td>Ball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Every, sort, of, tool, or, apparatus, had, ,,...</td>\n",
       "      <td>Ball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(For, the, world, of, science, and, evolution,...</td>\n",
       "      <td>Ball</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0     1\n",
       "0  (The, flying, ship, of, Professor, Lucifer, sa...  Ball\n",
       "1  (That, it, was, far, above, the, earth, was, n...  Ball\n",
       "2  (The, professor, had, himself, invented, the, ...  Ball\n",
       "3  (Every, sort, of, tool, or, apparatus, had, ,,...  Ball\n",
       "4  (For, the, world, of, science, and, evolution,...  Ball"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine the documents into a dataframe with identifier\n",
    "ball_df = [[sent, \"Ball\"] for sent in ball_sents]\n",
    "brown_df = [[sent, \"Brown\"] for sent in brown_sents]\n",
    "thursday_df = [[sent, \"Thursday\"] for sent in thursday_sents]\n",
    "\n",
    "sentences = pd.DataFrame(ball_df + brown_df + thursday_df)\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to create a list of the 750 most common words.\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # Filter out punctuation and stop words.\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    # Return the most common words.\n",
    "    return [item[0] for item in Counter(allwords).most_common(750)]\n",
    "    \n",
    "\n",
    "# Creates a data frame with features for each word in our common word set.\n",
    "# Each value is the count of the times the word appears in each sentence.\n",
    "def bow_features(sentences, common_words):\n",
    "    \n",
    "    # Scaffold the data frame and initialize counts to zero.\n",
    "    print('Setting up the Dataframe...')\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df['text_source'] = sentences[1]\n",
    "    df.loc[:, common_words] = 0\n",
    "    \n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        \n",
    "        # This counter is just to make sure the kernel didn't hang.\n",
    "        if i % 250 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "        \n",
    "        # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        \n",
    "        # Populate the row with word counts.\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1212"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up the bags.\n",
    "ball_words = bag_of_words(ball_doc)\n",
    "thursday_words = bag_of_words(thursday_doc)\n",
    "brown_words = bag_of_words(brown_doc)\n",
    "\n",
    "# Combine bags to create a set of unique words.\n",
    "common_words = set(ball_words + thursday_words + brown_words)\n",
    "len(common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up the Dataframe...\n",
      "Processing row 0\n",
      "Processing row 250\n",
      "Processing row 500\n",
      "Processing row 750\n",
      "Processing row 1000\n",
      "Processing row 1250\n",
      "Processing row 1500\n",
      "Processing row 1750\n",
      "Processing row 2000\n",
      "Processing row 2250\n",
      "Processing row 2500\n",
      "Processing row 2750\n",
      "Processing row 3000\n",
      "Processing row 3250\n",
      "Processing row 3500\n",
      "Processing row 3750\n",
      "Processing row 4000\n",
      "Processing row 4250\n",
      "Processing row 4500\n",
      "Processing row 4750\n",
      "Processing row 5000\n",
      "Processing row 5250\n",
      "Processing row 5500\n",
      "Processing row 5750\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>be</th>\n",
       "      <th>close</th>\n",
       "      <th>angle</th>\n",
       "      <th>nerve</th>\n",
       "      <th>shin</th>\n",
       "      <th>remark</th>\n",
       "      <th>different</th>\n",
       "      <th>mankind</th>\n",
       "      <th>duke</th>\n",
       "      <th>private</th>\n",
       "      <th>...</th>\n",
       "      <th>symbol</th>\n",
       "      <th>blade</th>\n",
       "      <th>purple</th>\n",
       "      <th>expect</th>\n",
       "      <th>dare</th>\n",
       "      <th>crawl</th>\n",
       "      <th>capture</th>\n",
       "      <th>longer</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(The, flying, ship, of, Professor, Lucifer, sa...</td>\n",
       "      <td>Ball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(That, it, was, far, above, the, earth, was, n...</td>\n",
       "      <td>Ball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(The, professor, had, himself, invented, the, ...</td>\n",
       "      <td>Ball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Every, sort, of, tool, or, apparatus, had, ,,...</td>\n",
       "      <td>Ball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(For, the, world, of, science, and, evolution,...</td>\n",
       "      <td>Ball</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1214 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  be close angle nerve shin remark different mankind duke private     ...      \\\n",
       "0  0     0     0     0    0      0         0       0    0       0     ...       \n",
       "1  0     0     0     0    0      0         0       0    0       0     ...       \n",
       "2  0     0     0     0    0      0         0       0    0       0     ...       \n",
       "3  0     0     0     0    0      0         0       0    0       0     ...       \n",
       "4  0     0     0     0    0      0         0       0    0       0     ...       \n",
       "\n",
       "  symbol blade purple expect dare crawl capture longer  \\\n",
       "0      0     0      0      0    0     0       0      0   \n",
       "1      0     0      0      0    0     0       0      0   \n",
       "2      0     0      0      0    0     0       0      0   \n",
       "3      0     0      0      0    0     0       0      0   \n",
       "4      0     0      0      0    0     0       0      0   \n",
       "\n",
       "                                       text_sentence text_source  \n",
       "0  (The, flying, ship, of, Professor, Lucifer, sa...        Ball  \n",
       "1  (That, it, was, far, above, the, earth, was, n...        Ball  \n",
       "2  (The, professor, had, himself, invented, the, ...        Ball  \n",
       "3  (Every, sort, of, tool, or, apparatus, had, ,,...        Ball  \n",
       "4  (For, the, world, of, science, and, evolution,...        Ball  \n",
       "\n",
       "[5 rows x 1214 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create our data frame with features\n",
    "word_counts = bow_features(sentences, common_words)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.9644444444444444\n",
      "\n",
      "Test set score: 0.6091666666666666\n"
     ]
    }
   ],
   "source": [
    "# random forest fitting\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "Y = word_counts['text_source']\n",
    "X = np.array(word_counts.drop(['text_sentence','text_source'], 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    Y,\n",
    "                                                    test_size=0.4,\n",
    "                                                    random_state=0)\n",
    "train = rfc.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score:', rfc.score(X_train, y_train))\n",
    "print('\\nTest set score:', rfc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3600, 1212) (3600,)\n",
      "Training set score: 0.8386111111111111\n",
      "\n",
      "Test set score: 0.6616666666666666\n"
     ]
    }
   ],
   "source": [
    "# logistic regression fitting\n",
    "lr = LogisticRegression()\n",
    "train = lr.fit(X_train, y_train)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print('Training set score:', lr.score(X_train, y_train))\n",
    "print('\\nTest set score:', lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.6822222222222222\n",
      "\n",
      "Test set score: 0.61375\n"
     ]
    }
   ],
   "source": [
    "# gradient boosting fitting\n",
    "clf = ensemble.GradientBoostingClassifier()\n",
    "train = clf.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score:', clf.score(X_train, y_train))\n",
    "print('\\nTest set score:', clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf-idf function\n",
    "def document_freq(data, sentences, common_words, doc_names, doc_words):\n",
    "    \n",
    "    # initialize df\n",
    "    df = pd.DataFrame(columns = common_words)\n",
    "    df.iloc[:, 0] = [0, 0, 0, 0, 0, 0]\n",
    "    df.loc[:, common_words] = 0\n",
    "    df.rename(index={0:'df', 1:'cf', 2:'idf', 3:'ball', 4:'brown', 5:'thursday'}, inplace=True)\n",
    "    \n",
    "    for word in common_words:\n",
    "        # drop words that aren't existing; problem due to the way common words are set up\n",
    "        if data.loc[:, word].sum() == 0:\n",
    "            df.drop([word], axis=1, inplace=True)\n",
    "            continue\n",
    "        \n",
    "        # find document frequency & collection frequency\n",
    "        df.loc['df', word] = data[data[word] > 0][word].count()\n",
    "        df.loc['cf', word] = data.loc[:, word].sum()\n",
    "        \n",
    "        # find idf\n",
    "        df.loc['idf', word] = np.log2(len(sentences)/df.loc['df', word])\n",
    "        \n",
    "    # assign the idf value to the documents\n",
    "    for word in df.columns:\n",
    "        for i in range(len(doc_names)):\n",
    "            if word in doc_words[i]:\n",
    "                df.loc[doc_names[i], word] = df.loc['idf', word]\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>be</th>\n",
       "      <th>close</th>\n",
       "      <th>angle</th>\n",
       "      <th>nerve</th>\n",
       "      <th>shin</th>\n",
       "      <th>remark</th>\n",
       "      <th>different</th>\n",
       "      <th>mankind</th>\n",
       "      <th>duke</th>\n",
       "      <th>private</th>\n",
       "      <th>...</th>\n",
       "      <th>end</th>\n",
       "      <th>worth</th>\n",
       "      <th>symbol</th>\n",
       "      <th>blade</th>\n",
       "      <th>purple</th>\n",
       "      <th>expect</th>\n",
       "      <th>dare</th>\n",
       "      <th>crawl</th>\n",
       "      <th>capture</th>\n",
       "      <th>longer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>df</th>\n",
       "      <td>243.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cf</th>\n",
       "      <td>265.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idf</th>\n",
       "      <td>4.625934</td>\n",
       "      <td>7.463284</td>\n",
       "      <td>9.550747</td>\n",
       "      <td>9.228819</td>\n",
       "      <td>8.850307</td>\n",
       "      <td>8.380822</td>\n",
       "      <td>8.643856</td>\n",
       "      <td>9.228819</td>\n",
       "      <td>8.027185</td>\n",
       "      <td>8.228819</td>\n",
       "      <td>...</td>\n",
       "      <td>6.141356</td>\n",
       "      <td>9.550747</td>\n",
       "      <td>8.850307</td>\n",
       "      <td>8.228819</td>\n",
       "      <td>8.643856</td>\n",
       "      <td>8.380822</td>\n",
       "      <td>9.091315</td>\n",
       "      <td>9.091315</td>\n",
       "      <td>8.850307</td>\n",
       "      <td>9.965784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ball</th>\n",
       "      <td>4.625934</td>\n",
       "      <td>7.463284</td>\n",
       "      <td>9.550747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.850307</td>\n",
       "      <td>8.380822</td>\n",
       "      <td>8.643856</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.141356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.228819</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.380822</td>\n",
       "      <td>9.091315</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.965784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brown</th>\n",
       "      <td>4.625934</td>\n",
       "      <td>7.463284</td>\n",
       "      <td>9.550747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.643856</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.027185</td>\n",
       "      <td>8.228819</td>\n",
       "      <td>...</td>\n",
       "      <td>6.141356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.228819</td>\n",
       "      <td>8.643856</td>\n",
       "      <td>8.380822</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.091315</td>\n",
       "      <td>8.850307</td>\n",
       "      <td>9.965784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thursday</th>\n",
       "      <td>4.625934</td>\n",
       "      <td>7.463284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.228819</td>\n",
       "      <td>8.850307</td>\n",
       "      <td>8.380822</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.228819</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.141356</td>\n",
       "      <td>9.550747</td>\n",
       "      <td>8.850307</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.380822</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 1184 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  be      close      angle      nerve       shin     remark  \\\n",
       "df        243.000000  34.000000   8.000000  10.000000  13.000000  18.000000   \n",
       "cf        265.000000  34.000000  10.000000  10.000000  14.000000  19.000000   \n",
       "idf         4.625934   7.463284   9.550747   9.228819   8.850307   8.380822   \n",
       "ball        4.625934   7.463284   9.550747   0.000000   8.850307   8.380822   \n",
       "brown       4.625934   7.463284   9.550747   0.000000   0.000000   0.000000   \n",
       "thursday    4.625934   7.463284   0.000000   9.228819   8.850307   8.380822   \n",
       "\n",
       "          different    mankind       duke    private    ...           end  \\\n",
       "df        15.000000  10.000000  23.000000  20.000000    ...     85.000000   \n",
       "cf        15.000000  11.000000  25.000000  20.000000    ...     87.000000   \n",
       "idf        8.643856   9.228819   8.027185   8.228819    ...      6.141356   \n",
       "ball       8.643856   0.000000   0.000000   0.000000    ...      6.141356   \n",
       "brown      8.643856   0.000000   8.027185   8.228819    ...      6.141356   \n",
       "thursday   0.000000   9.228819   0.000000   0.000000    ...      6.141356   \n",
       "\n",
       "             worth     symbol      blade     purple     expect       dare  \\\n",
       "df        8.000000  13.000000  20.000000  15.000000  18.000000  11.000000   \n",
       "cf        9.000000  14.000000  20.000000  15.000000  19.000000  11.000000   \n",
       "idf       9.550747   8.850307   8.228819   8.643856   8.380822   9.091315   \n",
       "ball      0.000000   0.000000   8.228819   0.000000   8.380822   9.091315   \n",
       "brown     0.000000   0.000000   8.228819   8.643856   8.380822   0.000000   \n",
       "thursday  9.550747   8.850307   0.000000   0.000000   8.380822   0.000000   \n",
       "\n",
       "              crawl    capture    longer  \n",
       "df        11.000000  13.000000  6.000000  \n",
       "cf        12.000000  14.000000  7.000000  \n",
       "idf        9.091315   8.850307  9.965784  \n",
       "ball       0.000000   0.000000  9.965784  \n",
       "brown      9.091315   8.850307  9.965784  \n",
       "thursday   0.000000   0.000000  0.000000  \n",
       "\n",
       "[6 rows x 1184 columns]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_names = ['ball', 'brown', 'thursday']\n",
    "doc_words = [ball_words, brown_words, thursday_words]\n",
    "tf_idf = document_freq(word_counts, sentences, common_words, doc_names, doc_words)\n",
    "tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>df</th>\n",
       "      <th>cf</th>\n",
       "      <th>idf</th>\n",
       "      <th>ball</th>\n",
       "      <th>brown</th>\n",
       "      <th>thursday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>be</th>\n",
       "      <td>243.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>4.625934</td>\n",
       "      <td>4.625934</td>\n",
       "      <td>4.625934</td>\n",
       "      <td>4.625934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>close</th>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>7.463284</td>\n",
       "      <td>7.463284</td>\n",
       "      <td>7.463284</td>\n",
       "      <td>7.463284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angle</th>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.550747</td>\n",
       "      <td>9.550747</td>\n",
       "      <td>9.550747</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nerve</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.228819</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.228819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shin</th>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.850307</td>\n",
       "      <td>8.850307</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.850307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          df     cf       idf      ball     brown  thursday\n",
       "be     243.0  265.0  4.625934  4.625934  4.625934  4.625934\n",
       "close   34.0   34.0  7.463284  7.463284  7.463284  7.463284\n",
       "angle    8.0   10.0  9.550747  9.550747  9.550747  0.000000\n",
       "nerve   10.0   10.0  9.228819  0.000000  0.000000  9.228819\n",
       "shin    13.0   14.0  8.850307  8.850307  0.000000  8.850307"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf.T.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test = train_test_split(brown_sents+ball_sents+thursday_sents, test_size=0.4, random_state=0)\n",
    "\n",
    "# vectorizer = TfidfVectorizer(max_df=0.5, # drop words that occur in more than half the paragraphs\n",
    "#                              min_df=2, # only use words that appear at least twice\n",
    "#                              stop_words=None, \n",
    "#                              lowercase=True, #convert everything to lower case (since Alice in Wonderland has the HABIT of CAPITALIZING WORDS for EMPHASIS)\n",
    "#                              use_idf=True,#we definitely want to use inverse document frequencies in our weighting\n",
    "#                              norm=u'l2', #Applies a correction factor so that longer paragraphs and shorter paragraphs get treated equally\n",
    "#                              smooth_idf=True #Adds 1 to all document frequencies, as if an extra document existed that used every word once.  Prevents divide-by-zero errors\n",
    "#                             )\n",
    "\n",
    "# #Applying the vectorizer\n",
    "# chesterton_tfidf = vectorizer.fit_transform(brown_doc)\n",
    "# print(\"Number of features: %d\" % chesterton_tfidf.get_shape()[1])\n",
    "\n",
    "# #splitting into training and test sets\n",
    "# X_train_tfidf, X_test_tfidf= train_test_split(chesterton_tfidf, test_size=0.4, random_state=0)\n",
    "\n",
    "# #Reshapes the vectorizer output into something people can read\n",
    "# X_train_tfidf_csr = X_train_tfidf.tocsr()\n",
    "\n",
    "# #number of sentences\n",
    "# n = X_train_tfidf_csr.shape[0]\n",
    "# #A list of dictionaries, one per sentence\n",
    "# tfidf_bysent = [{} for _ in range(0,n)]\n",
    "# #List of features\n",
    "# terms = vectorizer.get_feature_names()\n",
    "# #for each paragraph, lists the feature words and their tf-idf scores\n",
    "# for i, j in zip(*X_train_tfidf_csr.nonzero()):\n",
    "#     tfidf_bysent[i][terms[j]] = X_train_tfidf_csr[i, j]\n",
    "    \n",
    "# #Keep in mind that the log base 2 of 1 is 0, so a tf-idf score of 0 indicates that the word was present once in that sentence.\n",
    "# print('Original sentence:', X_train[5])\n",
    "# print('Tf_idf vector:', tfidf_bysent[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reduce feature set\n",
    "# svd = TruncatedSVD(330)\n",
    "# lsa = make_pipeline(svd, Normalizer(copy=False))\n",
    "\n",
    "# # run SVD on training data then project on training data\n",
    "# X_train_lsa = lsa.fit_transform(X_train_tf)\n",
    "\n",
    "# variance_explained = svd.explained_variance_ratio_\n",
    "# total_variance = variance_explained.sum()\n",
    "# print(\"Percent variance captured by all components:\", total_variance*100)\n",
    "\n",
    "# #Looking at what sorts of paragraphs our solution considers similar, for the first five identified topics\n",
    "# paras_by_component=pd.DataFrame(X_train_lsa,index=X_train)\n",
    "# for i in range(5):\n",
    "#     print('Component {}:'.format(i))\n",
    "#     print(paras_by_component.loc[:,i].sort_values(ascending=False)[0:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
