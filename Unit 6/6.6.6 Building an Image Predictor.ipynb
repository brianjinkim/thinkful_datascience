{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allocates GPU memory based on runtime allocations. doesn't releases memory because of potential memory fragmentation\n",
    "# without this option, getting images will not work\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "nb_train_samples = 844\n",
    "nb_validation_samples = 362\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the augmentation configuration for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the augmentation configuration we will use for testing:\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 844 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 359 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "22/22 [==============================] - 5s 217ms/step - loss: 0.7247 - acc: 0.4630 - val_loss: 0.6887 - val_acc: 0.5766\n",
      "Epoch 2/50\n",
      "22/22 [==============================] - 3s 121ms/step - loss: 0.6961 - acc: 0.5170 - val_loss: 0.6914 - val_acc: 0.6072\n",
      "Epoch 3/50\n",
      "22/22 [==============================] - 3s 130ms/step - loss: 0.6971 - acc: 0.5142 - val_loss: 0.6881 - val_acc: 0.5042\n",
      "Epoch 4/50\n",
      "22/22 [==============================] - 3s 128ms/step - loss: 0.6965 - acc: 0.5369 - val_loss: 0.6796 - val_acc: 0.5989\n",
      "Epoch 5/50\n",
      "22/22 [==============================] - 3s 127ms/step - loss: 0.6902 - acc: 0.5606 - val_loss: 0.6751 - val_acc: 0.4680\n",
      "Epoch 6/50\n",
      "22/22 [==============================] - 3s 127ms/step - loss: 0.6827 - acc: 0.5795 - val_loss: 0.6376 - val_acc: 0.6630\n",
      "Epoch 7/50\n",
      "22/22 [==============================] - 3s 129ms/step - loss: 0.6990 - acc: 0.5256 - val_loss: 0.6556 - val_acc: 0.7047\n",
      "Epoch 8/50\n",
      "22/22 [==============================] - 3s 129ms/step - loss: 0.6783 - acc: 0.5653 - val_loss: 0.6372 - val_acc: 0.6908\n",
      "Epoch 9/50\n",
      "22/22 [==============================] - 3s 127ms/step - loss: 0.6681 - acc: 0.5683 - val_loss: 0.6165 - val_acc: 0.7019\n",
      "Epoch 10/50\n",
      "22/22 [==============================] - 3s 128ms/step - loss: 0.6643 - acc: 0.5938 - val_loss: 0.6092 - val_acc: 0.7214\n",
      "Epoch 11/50\n",
      "22/22 [==============================] - 3s 128ms/step - loss: 0.6912 - acc: 0.6420 - val_loss: 0.6022 - val_acc: 0.6657\n",
      "Epoch 12/50\n",
      "22/22 [==============================] - 3s 127ms/step - loss: 0.6502 - acc: 0.6336 - val_loss: 0.5968 - val_acc: 0.6964\n",
      "Epoch 13/50\n",
      "22/22 [==============================] - 3s 149ms/step - loss: 0.6686 - acc: 0.5966 - val_loss: 0.6580 - val_acc: 0.6072\n",
      "Epoch 14/50\n",
      "22/22 [==============================] - 3s 127ms/step - loss: 0.6088 - acc: 0.6136 - val_loss: 0.5737 - val_acc: 0.7019\n",
      "Epoch 15/50\n",
      "22/22 [==============================] - 3s 129ms/step - loss: 0.6338 - acc: 0.6696 - val_loss: 0.5878 - val_acc: 0.7047\n",
      "Epoch 16/50\n",
      "22/22 [==============================] - 3s 129ms/step - loss: 0.6192 - acc: 0.6392 - val_loss: 0.5638 - val_acc: 0.7577\n",
      "Epoch 17/50\n",
      "22/22 [==============================] - 3s 130ms/step - loss: 0.6351 - acc: 0.6562 - val_loss: 0.5583 - val_acc: 0.7409\n",
      "Epoch 18/50\n",
      "22/22 [==============================] - 3s 127ms/step - loss: 0.5944 - acc: 0.6885 - val_loss: 0.5684 - val_acc: 0.7270\n",
      "Epoch 19/50\n",
      "22/22 [==============================] - 3s 128ms/step - loss: 0.6169 - acc: 0.6534 - val_loss: 0.5503 - val_acc: 0.7409\n",
      "Epoch 20/50\n",
      "22/22 [==============================] - 3s 133ms/step - loss: 0.5830 - acc: 0.6676 - val_loss: 0.7687 - val_acc: 0.6240\n",
      "Epoch 21/50\n",
      "22/22 [==============================] - 3s 127ms/step - loss: 0.6045 - acc: 0.6771 - val_loss: 0.6485 - val_acc: 0.6825\n",
      "Epoch 22/50\n",
      "22/22 [==============================] - 3s 137ms/step - loss: 0.5966 - acc: 0.6619 - val_loss: 0.5155 - val_acc: 0.7549\n",
      "Epoch 23/50\n",
      "22/22 [==============================] - 3s 133ms/step - loss: 0.6053 - acc: 0.6676 - val_loss: 0.5516 - val_acc: 0.7716\n",
      "Epoch 24/50\n",
      "22/22 [==============================] - 3s 127ms/step - loss: 0.5930 - acc: 0.6752 - val_loss: 0.5477 - val_acc: 0.7577\n",
      "Epoch 25/50\n",
      "22/22 [==============================] - 3s 147ms/step - loss: 0.6154 - acc: 0.6990 - val_loss: 0.5299 - val_acc: 0.7465\n",
      "Epoch 26/50\n",
      "22/22 [==============================] - 3s 134ms/step - loss: 0.5721 - acc: 0.7244 - val_loss: 0.5169 - val_acc: 0.7660\n",
      "Epoch 27/50\n",
      "22/22 [==============================] - 3s 131ms/step - loss: 0.5646 - acc: 0.7131 - val_loss: 0.5208 - val_acc: 0.7883\n",
      "Epoch 28/50\n",
      "22/22 [==============================] - 3s 130ms/step - loss: 0.5381 - acc: 0.7273 - val_loss: 0.5504 - val_acc: 0.7911\n",
      "Epoch 29/50\n",
      "22/22 [==============================] - 3s 135ms/step - loss: 0.5963 - acc: 0.6932 - val_loss: 0.5341 - val_acc: 0.7772\n",
      "Epoch 30/50\n",
      "22/22 [==============================] - 3s 129ms/step - loss: 0.5632 - acc: 0.7301 - val_loss: 0.6081 - val_acc: 0.7521\n",
      "Epoch 31/50\n",
      "22/22 [==============================] - 3s 132ms/step - loss: 0.5167 - acc: 0.7443 - val_loss: 0.5642 - val_acc: 0.7187\n",
      "Epoch 32/50\n",
      "22/22 [==============================] - 3s 130ms/step - loss: 0.5377 - acc: 0.7386 - val_loss: 0.5516 - val_acc: 0.7827\n",
      "Epoch 33/50\n",
      "22/22 [==============================] - 3s 127ms/step - loss: 0.4977 - acc: 0.7415 - val_loss: 0.5110 - val_acc: 0.7799\n",
      "Epoch 34/50\n",
      "22/22 [==============================] - 3s 130ms/step - loss: 0.5129 - acc: 0.7045 - val_loss: 0.6744 - val_acc: 0.7159\n",
      "Epoch 35/50\n",
      "22/22 [==============================] - 3s 139ms/step - loss: 0.5171 - acc: 0.7177 - val_loss: 0.5405 - val_acc: 0.7939\n",
      "Epoch 36/50\n",
      "22/22 [==============================] - 3s 144ms/step - loss: 0.5379 - acc: 0.7074 - val_loss: 0.6775 - val_acc: 0.7159\n",
      "Epoch 37/50\n",
      "22/22 [==============================] - 3s 142ms/step - loss: 0.4887 - acc: 0.7811 - val_loss: 0.5160 - val_acc: 0.7994\n",
      "Epoch 38/50\n",
      "22/22 [==============================] - 3s 129ms/step - loss: 0.5248 - acc: 0.7330 - val_loss: 0.5354 - val_acc: 0.7437\n",
      "Epoch 39/50\n",
      "22/22 [==============================] - 3s 130ms/step - loss: 0.4919 - acc: 0.7443 - val_loss: 0.5348 - val_acc: 0.7716\n",
      "Epoch 40/50\n",
      "22/22 [==============================] - 3s 131ms/step - loss: 0.5275 - acc: 0.7386 - val_loss: 0.5601 - val_acc: 0.7521\n",
      "Epoch 41/50\n",
      "22/22 [==============================] - 3s 129ms/step - loss: 0.5028 - acc: 0.7633 - val_loss: 0.5487 - val_acc: 0.7716\n",
      "Epoch 42/50\n",
      "22/22 [==============================] - 3s 129ms/step - loss: 0.4617 - acc: 0.7784 - val_loss: 0.7476 - val_acc: 0.7187\n",
      "Epoch 43/50\n",
      "22/22 [==============================] - 3s 130ms/step - loss: 0.4722 - acc: 0.7680 - val_loss: 0.5213 - val_acc: 0.7688\n",
      "Epoch 44/50\n",
      "22/22 [==============================] - 3s 131ms/step - loss: 0.4772 - acc: 0.7973 - val_loss: 0.5180 - val_acc: 0.7967\n",
      "Epoch 45/50\n",
      "22/22 [==============================] - 3s 132ms/step - loss: 0.4992 - acc: 0.7528 - val_loss: 0.5088 - val_acc: 0.7799\n",
      "Epoch 46/50\n",
      "22/22 [==============================] - 3s 130ms/step - loss: 0.4174 - acc: 0.8040 - val_loss: 0.5688 - val_acc: 0.7883\n",
      "Epoch 47/50\n",
      "22/22 [==============================] - 3s 129ms/step - loss: 0.4993 - acc: 0.7727 - val_loss: 0.5434 - val_acc: 0.7883\n",
      "Epoch 48/50\n",
      "22/22 [==============================] - 3s 132ms/step - loss: 0.4292 - acc: 0.8134 - val_loss: 0.6889 - val_acc: 0.7354\n",
      "Epoch 49/50\n",
      "22/22 [==============================] - 3s 137ms/step - loss: 0.4200 - acc: 0.7926 - val_loss: 0.6113 - val_acc: 0.7911\n",
      "Epoch 50/50\n",
      "22/22 [==============================] - 3s 132ms/step - loss: 0.5000 - acc: 0.7747 - val_loss: 0.5258 - val_acc: 0.7939\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size\n",
    ")\n",
    "\n",
    "model.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 148, 148, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 72, 72, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 72, 72, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 36, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 34, 34, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 34, 34, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 17, 17, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18496)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                1183808   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,212,513\n",
      "Trainable params: 1,212,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = Sequential()\n",
    "\n",
    "loaded_model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "loaded_model.add(Activation('relu'))\n",
    "loaded_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "loaded_model.add(Conv2D(32, (3, 3)))\n",
    "loaded_model.add(Activation('relu'))\n",
    "loaded_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "loaded_model.add(Conv2D(64, (3, 3)))\n",
    "loaded_model.add(Activation('relu'))\n",
    "loaded_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "loaded_model.add(Flatten())\n",
    "loaded_model.add(Dense(64))\n",
    "loaded_model.add(Activation('relu'))\n",
    "loaded_model.add(Dropout(0.5))\n",
    "loaded_model.add(Dense(1))\n",
    "loaded_model.add(Activation('sigmoid'))\n",
    "\n",
    "loaded_model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "loaded_model.load_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 1s 43ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = loaded_model.predict_generator(validation_generator, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[111,  96],\n",
       "       [ 92,  60]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "y_true = np.array([0] * 207 + [1] * 152)\n",
    "y_pred = prediction > 0.5\n",
    "\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(359, 1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "22/22 [==============================] - 3s 154ms/step - loss: 0.7364 - acc: 0.4375 - val_loss: 0.6928 - val_acc: 0.5599\n",
      "Epoch 2/50\n",
      "22/22 [==============================] - 3s 129ms/step - loss: 0.6956 - acc: 0.4915 - val_loss: 0.6939 - val_acc: 0.4234\n",
      "Epoch 3/50\n",
      "22/22 [==============================] - 3s 135ms/step - loss: 0.6957 - acc: 0.4650 - val_loss: 0.6959 - val_acc: 0.4234\n",
      "Epoch 4/50\n",
      "22/22 [==============================] - 3s 134ms/step - loss: 0.6933 - acc: 0.5142 - val_loss: 0.6874 - val_acc: 0.5766\n",
      "Epoch 5/50\n",
      "22/22 [==============================] - 3s 136ms/step - loss: 0.6997 - acc: 0.4830 - val_loss: 0.6940 - val_acc: 0.4234\n",
      "Epoch 6/50\n",
      "22/22 [==============================] - 3s 130ms/step - loss: 0.6931 - acc: 0.5057 - val_loss: 0.6974 - val_acc: 0.4234\n",
      "Epoch 7/50\n",
      "22/22 [==============================] - 3s 129ms/step - loss: 0.6942 - acc: 0.4897 - val_loss: 0.7239 - val_acc: 0.4234\n",
      "Epoch 8/50\n",
      "22/22 [==============================] - 3s 135ms/step - loss: 0.6926 - acc: 0.5398 - val_loss: 0.7309 - val_acc: 0.4290\n",
      "Epoch 9/50\n",
      "22/22 [==============================] - 3s 130ms/step - loss: 0.7035 - acc: 0.5370 - val_loss: 0.6833 - val_acc: 0.7047\n",
      "Epoch 10/50\n",
      "22/22 [==============================] - 3s 132ms/step - loss: 0.6894 - acc: 0.5682 - val_loss: 0.6891 - val_acc: 0.4903\n",
      "Epoch 11/50\n",
      "22/22 [==============================] - 3s 129ms/step - loss: 0.6999 - acc: 0.5739 - val_loss: 0.6919 - val_acc: 0.4485\n",
      "Epoch 12/50\n",
      "22/22 [==============================] - 3s 130ms/step - loss: 0.6901 - acc: 0.5691 - val_loss: 0.6547 - val_acc: 0.6602\n",
      "Epoch 13/50\n",
      "22/22 [==============================] - 3s 147ms/step - loss: 0.7301 - acc: 0.5767 - val_loss: 0.6564 - val_acc: 0.6184\n",
      "Epoch 14/50\n",
      "22/22 [==============================] - 3s 130ms/step - loss: 0.6616 - acc: 0.6345 - val_loss: 0.6167 - val_acc: 0.6741\n",
      "Epoch 15/50\n",
      "22/22 [==============================] - 3s 135ms/step - loss: 0.6496 - acc: 0.6051 - val_loss: 0.5868 - val_acc: 0.7382\n",
      "Epoch 16/50\n",
      "22/22 [==============================] - 3s 129ms/step - loss: 0.6794 - acc: 0.6136 - val_loss: 0.5818 - val_acc: 0.7075\n",
      "Epoch 17/50\n",
      "22/22 [==============================] - 3s 134ms/step - loss: 0.6603 - acc: 0.6261 - val_loss: 0.5944 - val_acc: 0.6880\n",
      "Epoch 18/50\n",
      "22/22 [==============================] - 3s 133ms/step - loss: 0.6518 - acc: 0.6648 - val_loss: 0.5895 - val_acc: 0.7187\n",
      "Epoch 19/50\n",
      "22/22 [==============================] - 3s 131ms/step - loss: 0.6239 - acc: 0.6885 - val_loss: 0.5708 - val_acc: 0.7382\n",
      "Epoch 20/50\n",
      "22/22 [==============================] - 3s 130ms/step - loss: 0.6552 - acc: 0.6240 - val_loss: 0.5862 - val_acc: 0.7214\n",
      "Epoch 21/50\n",
      "22/22 [==============================] - 3s 130ms/step - loss: 0.6282 - acc: 0.6818 - val_loss: 0.5368 - val_acc: 0.7354\n",
      "Epoch 22/50\n",
      "22/22 [==============================] - 3s 135ms/step - loss: 0.6344 - acc: 0.6705 - val_loss: 0.5440 - val_acc: 0.7131\n",
      "Epoch 23/50\n",
      "22/22 [==============================] - 3s 131ms/step - loss: 0.6001 - acc: 0.6989 - val_loss: 0.5487 - val_acc: 0.7521\n",
      "Epoch 24/50\n",
      "22/22 [==============================] - 3s 129ms/step - loss: 0.6011 - acc: 0.7045 - val_loss: 0.5378 - val_acc: 0.7298\n",
      "Epoch 25/50\n",
      "22/22 [==============================] - 3s 145ms/step - loss: 0.6226 - acc: 0.6629 - val_loss: 0.5177 - val_acc: 0.7716\n",
      "Epoch 26/50\n",
      "22/22 [==============================] - 3s 128ms/step - loss: 0.5875 - acc: 0.6818 - val_loss: 0.5894 - val_acc: 0.6908\n",
      "Epoch 27/50\n",
      "22/22 [==============================] - 3s 130ms/step - loss: 0.6044 - acc: 0.7026 - val_loss: 0.5495 - val_acc: 0.7382\n",
      "Epoch 28/50\n",
      "22/22 [==============================] - 3s 131ms/step - loss: 0.6163 - acc: 0.6591 - val_loss: 0.5919 - val_acc: 0.7131\n",
      "Epoch 29/50\n",
      "22/22 [==============================] - 3s 137ms/step - loss: 0.5955 - acc: 0.6761 - val_loss: 0.5604 - val_acc: 0.7493\n",
      "Epoch 30/50\n",
      "22/22 [==============================] - 3s 129ms/step - loss: 0.6078 - acc: 0.6534 - val_loss: 0.5524 - val_acc: 0.7577\n",
      "Epoch 31/50\n",
      "22/22 [==============================] - 3s 128ms/step - loss: 0.5733 - acc: 0.6903 - val_loss: 0.5526 - val_acc: 0.7493\n",
      "Epoch 32/50\n",
      "22/22 [==============================] - 3s 136ms/step - loss: 0.5361 - acc: 0.7330 - val_loss: 0.5177 - val_acc: 0.7660\n",
      "Epoch 33/50\n",
      "22/22 [==============================] - 3s 131ms/step - loss: 0.5745 - acc: 0.6989 - val_loss: 0.5670 - val_acc: 0.7214\n",
      "Epoch 34/50\n",
      "22/22 [==============================] - 3s 135ms/step - loss: 0.5882 - acc: 0.6932 - val_loss: 0.8126 - val_acc: 0.6574\n",
      "Epoch 35/50\n",
      "22/22 [==============================] - 3s 131ms/step - loss: 0.6173 - acc: 0.6875 - val_loss: 0.6008 - val_acc: 0.6964\n",
      "Epoch 36/50\n",
      "22/22 [==============================] - 3s 129ms/step - loss: 0.5404 - acc: 0.7093 - val_loss: 0.6205 - val_acc: 0.7354\n",
      "Epoch 37/50\n",
      "22/22 [==============================] - 3s 138ms/step - loss: 0.5927 - acc: 0.7074 - val_loss: 0.5161 - val_acc: 0.7772\n",
      "Epoch 38/50\n",
      "22/22 [==============================] - 3s 127ms/step - loss: 0.5625 - acc: 0.7075 - val_loss: 0.5987 - val_acc: 0.6964\n",
      "Epoch 39/50\n",
      "22/22 [==============================] - 3s 130ms/step - loss: 0.5399 - acc: 0.7159 - val_loss: 0.6296 - val_acc: 0.6880\n",
      "Epoch 40/50\n",
      "22/22 [==============================] - 3s 128ms/step - loss: 0.5867 - acc: 0.6846 - val_loss: 0.5970 - val_acc: 0.6852\n",
      "Epoch 41/50\n",
      "22/22 [==============================] - 3s 136ms/step - loss: 0.5364 - acc: 0.7528 - val_loss: 0.6182 - val_acc: 0.6797\n",
      "Epoch 42/50\n",
      "22/22 [==============================] - 3s 131ms/step - loss: 0.5542 - acc: 0.7036 - val_loss: 0.5771 - val_acc: 0.6908\n",
      "Epoch 43/50\n",
      "22/22 [==============================] - 3s 131ms/step - loss: 0.5498 - acc: 0.7500 - val_loss: 0.5936 - val_acc: 0.7326\n",
      "Epoch 44/50\n",
      "22/22 [==============================] - 3s 136ms/step - loss: 0.4815 - acc: 0.7670 - val_loss: 0.5303 - val_acc: 0.7549\n",
      "Epoch 45/50\n",
      "22/22 [==============================] - 3s 130ms/step - loss: 0.5737 - acc: 0.7386 - val_loss: 0.7458 - val_acc: 0.6657\n",
      "Epoch 46/50\n",
      "22/22 [==============================] - 3s 130ms/step - loss: 0.5150 - acc: 0.7443 - val_loss: 0.5763 - val_acc: 0.7214\n",
      "Epoch 47/50\n",
      "22/22 [==============================] - 3s 129ms/step - loss: 0.5081 - acc: 0.7614 - val_loss: 0.5899 - val_acc: 0.7187\n",
      "Epoch 48/50\n",
      "22/22 [==============================] - 3s 127ms/step - loss: 0.4728 - acc: 0.7689 - val_loss: 0.6312 - val_acc: 0.7521\n",
      "Epoch 49/50\n",
      "22/22 [==============================] - 3s 133ms/step - loss: 0.5329 - acc: 0.7548 - val_loss: 0.5329 - val_acc: 0.7577\n",
      "Epoch 50/50\n",
      "22/22 [==============================] - 3s 130ms/step - loss: 0.5370 - acc: 0.7330 - val_loss: 0.5769 - val_acc: 0.7437\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size\n",
    ")\n",
    "\n",
    "model.save_weights('3ConvLayer.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 1s 43ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict_generator(validation_generator, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[108,  99],\n",
       "       [ 75,  77]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = np.array([0] * 207 + [1] * 152)\n",
    "y_pred = prediction > 0.5\n",
    "\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "52/52 [==============================] - 7s 138ms/step - loss: 7.9138 - acc: 0.4948 - val_loss: 9.1924 - val_acc: 0.4234\n",
      "Epoch 2/50\n",
      "52/52 [==============================] - 7s 137ms/step - loss: 5.8671 - acc: 0.4836 - val_loss: 0.7455 - val_acc: 0.4345\n",
      "Epoch 3/50\n",
      "52/52 [==============================] - 7s 135ms/step - loss: 0.6881 - acc: 0.5881 - val_loss: 0.6421 - val_acc: 0.6267\n",
      "Epoch 4/50\n",
      "52/52 [==============================] - 7s 133ms/step - loss: 0.6597 - acc: 0.6286 - val_loss: 0.5980 - val_acc: 0.6852\n",
      "Epoch 5/50\n",
      "52/52 [==============================] - 7s 130ms/step - loss: 0.6473 - acc: 0.6378 - val_loss: 0.6385 - val_acc: 0.6630\n",
      "Epoch 6/50\n",
      "52/52 [==============================] - 7s 128ms/step - loss: 0.6246 - acc: 0.6578 - val_loss: 0.6284 - val_acc: 0.6992\n",
      "Epoch 7/50\n",
      "52/52 [==============================] - 7s 129ms/step - loss: 0.6110 - acc: 0.6923 - val_loss: 0.6270 - val_acc: 0.7159\n",
      "Epoch 8/50\n",
      "52/52 [==============================] - 7s 129ms/step - loss: 0.5971 - acc: 0.7075 - val_loss: 0.7457 - val_acc: 0.6240\n",
      "Epoch 9/50\n",
      "52/52 [==============================] - 7s 130ms/step - loss: 0.5742 - acc: 0.6999 - val_loss: 0.6486 - val_acc: 0.7131\n",
      "Epoch 10/50\n",
      "52/52 [==============================] - 7s 128ms/step - loss: 0.5646 - acc: 0.7207 - val_loss: 0.6649 - val_acc: 0.6992\n",
      "Epoch 11/50\n",
      "52/52 [==============================] - 7s 131ms/step - loss: 0.5631 - acc: 0.7103 - val_loss: 0.8531 - val_acc: 0.6407\n",
      "Epoch 12/50\n",
      "52/52 [==============================] - 7s 128ms/step - loss: 0.5376 - acc: 0.7279 - val_loss: 0.6966 - val_acc: 0.6769\n",
      "Epoch 13/50\n",
      "52/52 [==============================] - 7s 128ms/step - loss: 0.5503 - acc: 0.7532 - val_loss: 0.7940 - val_acc: 0.6908\n",
      "Epoch 14/50\n",
      "52/52 [==============================] - 7s 129ms/step - loss: 0.5633 - acc: 0.7284 - val_loss: 0.6900 - val_acc: 0.7187\n",
      "Epoch 15/50\n",
      "52/52 [==============================] - 7s 128ms/step - loss: 0.5269 - acc: 0.7612 - val_loss: 0.6673 - val_acc: 0.7214\n",
      "Epoch 16/50\n",
      "52/52 [==============================] - 7s 128ms/step - loss: 0.5110 - acc: 0.7612 - val_loss: 0.7683 - val_acc: 0.7131\n",
      "Epoch 17/50\n",
      "52/52 [==============================] - 7s 129ms/step - loss: 0.5439 - acc: 0.7596 - val_loss: 0.6687 - val_acc: 0.7187\n",
      "Epoch 18/50\n",
      "52/52 [==============================] - 7s 129ms/step - loss: 0.5438 - acc: 0.7748 - val_loss: 0.7236 - val_acc: 0.7047\n",
      "Epoch 19/50\n",
      "52/52 [==============================] - 7s 132ms/step - loss: 0.4898 - acc: 0.7788 - val_loss: 0.6852 - val_acc: 0.7270\n",
      "Epoch 20/50\n",
      "52/52 [==============================] - 7s 129ms/step - loss: 0.5248 - acc: 0.7709 - val_loss: 0.7475 - val_acc: 0.6964\n",
      "Epoch 21/50\n",
      "52/52 [==============================] - 7s 130ms/step - loss: 0.4693 - acc: 0.7877 - val_loss: 0.6840 - val_acc: 0.7159\n",
      "Epoch 22/50\n",
      "52/52 [==============================] - 7s 133ms/step - loss: 0.4668 - acc: 0.7985 - val_loss: 0.8296 - val_acc: 0.7354\n",
      "Epoch 23/50\n",
      "52/52 [==============================] - 7s 132ms/step - loss: 0.4863 - acc: 0.7748 - val_loss: 0.6991 - val_acc: 0.7298\n",
      "Epoch 24/50\n",
      "52/52 [==============================] - 7s 132ms/step - loss: 0.4607 - acc: 0.8137 - val_loss: 0.7472 - val_acc: 0.7409\n",
      "Epoch 25/50\n",
      "52/52 [==============================] - 7s 133ms/step - loss: 0.4702 - acc: 0.7768 - val_loss: 0.6468 - val_acc: 0.7354\n",
      "Epoch 26/50\n",
      "52/52 [==============================] - 7s 131ms/step - loss: 0.4649 - acc: 0.7893 - val_loss: 0.7314 - val_acc: 0.7326\n",
      "Epoch 27/50\n",
      "52/52 [==============================] - 7s 130ms/step - loss: 0.4658 - acc: 0.8093 - val_loss: 0.7348 - val_acc: 0.7382\n",
      "Epoch 28/50\n",
      "52/52 [==============================] - 7s 128ms/step - loss: 0.4178 - acc: 0.8233 - val_loss: 0.8796 - val_acc: 0.7326\n",
      "Epoch 29/50\n",
      "52/52 [==============================] - 7s 130ms/step - loss: 0.4351 - acc: 0.8189 - val_loss: 0.8487 - val_acc: 0.7493\n",
      "Epoch 30/50\n",
      "52/52 [==============================] - 7s 130ms/step - loss: 0.4541 - acc: 0.8173 - val_loss: 0.6938 - val_acc: 0.7437\n",
      "Epoch 31/50\n",
      "52/52 [==============================] - 7s 131ms/step - loss: 0.4174 - acc: 0.8173 - val_loss: 0.9014 - val_acc: 0.7075\n",
      "Epoch 32/50\n",
      "52/52 [==============================] - 7s 140ms/step - loss: 0.3823 - acc: 0.8341 - val_loss: 1.0004 - val_acc: 0.7075\n",
      "Epoch 33/50\n",
      "52/52 [==============================] - 7s 128ms/step - loss: 0.4391 - acc: 0.8181 - val_loss: 0.9969 - val_acc: 0.6852\n",
      "Epoch 34/50\n",
      "52/52 [==============================] - 7s 132ms/step - loss: 0.4414 - acc: 0.8161 - val_loss: 0.8816 - val_acc: 0.7159\n",
      "Epoch 35/50\n",
      "52/52 [==============================] - 7s 137ms/step - loss: 0.4250 - acc: 0.8257 - val_loss: 1.0977 - val_acc: 0.6992\n",
      "Epoch 36/50\n",
      "52/52 [==============================] - 7s 141ms/step - loss: 0.4171 - acc: 0.8401 - val_loss: 0.8262 - val_acc: 0.7354\n",
      "Epoch 37/50\n",
      "52/52 [==============================] - 7s 133ms/step - loss: 0.3830 - acc: 0.8433 - val_loss: 0.9555 - val_acc: 0.7103\n",
      "Epoch 38/50\n",
      "52/52 [==============================] - 7s 134ms/step - loss: 0.3773 - acc: 0.8269 - val_loss: 1.0323 - val_acc: 0.7214\n",
      "Epoch 39/50\n",
      "52/52 [==============================] - 7s 134ms/step - loss: 0.3981 - acc: 0.8462 - val_loss: 0.9229 - val_acc: 0.7326\n",
      "Epoch 40/50\n",
      "52/52 [==============================] - 7s 136ms/step - loss: 0.3839 - acc: 0.8594 - val_loss: 0.8242 - val_acc: 0.7326\n",
      "Epoch 41/50\n",
      "52/52 [==============================] - 7s 133ms/step - loss: 0.3873 - acc: 0.8530 - val_loss: 1.0577 - val_acc: 0.7187\n",
      "Epoch 42/50\n",
      "52/52 [==============================] - 7s 136ms/step - loss: 0.3623 - acc: 0.8562 - val_loss: 0.8340 - val_acc: 0.7382\n",
      "Epoch 43/50\n",
      "52/52 [==============================] - 7s 135ms/step - loss: 0.3633 - acc: 0.8466 - val_loss: 0.7840 - val_acc: 0.7326\n",
      "Epoch 44/50\n",
      "52/52 [==============================] - 7s 136ms/step - loss: 0.3516 - acc: 0.8542 - val_loss: 0.8174 - val_acc: 0.7326\n",
      "Epoch 45/50\n",
      "52/52 [==============================] - 7s 143ms/step - loss: 0.3995 - acc: 0.8578 - val_loss: 0.9168 - val_acc: 0.7465\n",
      "Epoch 46/50\n",
      "52/52 [==============================] - 7s 131ms/step - loss: 0.3361 - acc: 0.8461 - val_loss: 0.9146 - val_acc: 0.7437\n",
      "Epoch 47/50\n",
      "52/52 [==============================] - 7s 139ms/step - loss: 0.3551 - acc: 0.8762 - val_loss: 0.8512 - val_acc: 0.7465\n",
      "Epoch 48/50\n",
      "52/52 [==============================] - 7s 136ms/step - loss: 0.3462 - acc: 0.8654 - val_loss: 0.8600 - val_acc: 0.7465\n",
      "Epoch 49/50\n",
      "52/52 [==============================] - 7s 134ms/step - loss: 0.3151 - acc: 0.8898 - val_loss: 1.0173 - val_acc: 0.7326\n",
      "Epoch 50/50\n",
      "52/52 [==============================] - 7s 131ms/step - loss: 0.3457 - acc: 0.8650 - val_loss: 0.8848 - val_acc: 0.7465\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size\n",
    ")\n",
    "\n",
    "model.save_weights('1ConvLayer.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 1s 53ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict_generator(validation_generator, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 96, 111],\n",
       "       [ 82,  70]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = np.array([0] * 207 + [1] * 152)\n",
    "y_pred = prediction > 0.5\n",
    "\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "52/52 [==============================] - 8s 152ms/step - loss: 0.7002 - acc: 0.5164 - val_loss: 0.6987 - val_acc: 0.4234\n",
      "Epoch 2/250\n",
      "52/52 [==============================] - 7s 141ms/step - loss: 0.6953 - acc: 0.4964 - val_loss: 0.6926 - val_acc: 0.5515\n",
      "Epoch 3/250\n",
      "52/52 [==============================] - 7s 137ms/step - loss: 0.7031 - acc: 0.5240 - val_loss: 0.6845 - val_acc: 0.5766\n",
      "Epoch 4/250\n",
      "52/52 [==============================] - 7s 135ms/step - loss: 0.6946 - acc: 0.5232 - val_loss: 0.7155 - val_acc: 0.4234\n",
      "Epoch 5/250\n",
      "52/52 [==============================] - 7s 134ms/step - loss: 0.6927 - acc: 0.5393 - val_loss: 0.6752 - val_acc: 0.5933\n",
      "Epoch 6/250\n",
      "52/52 [==============================] - 7s 135ms/step - loss: 0.6841 - acc: 0.5889 - val_loss: 0.6350 - val_acc: 0.6964\n",
      "Epoch 7/250\n",
      "52/52 [==============================] - 7s 136ms/step - loss: 0.6704 - acc: 0.5849 - val_loss: 0.5820 - val_acc: 0.7075\n",
      "Epoch 8/250\n",
      "52/52 [==============================] - 7s 133ms/step - loss: 0.6613 - acc: 0.6038 - val_loss: 0.6173 - val_acc: 0.6685\n",
      "Epoch 9/250\n",
      "52/52 [==============================] - 7s 133ms/step - loss: 0.6401 - acc: 0.6414 - val_loss: 0.5468 - val_acc: 0.7131\n",
      "Epoch 10/250\n",
      "52/52 [==============================] - 7s 136ms/step - loss: 0.6302 - acc: 0.6707 - val_loss: 0.5611 - val_acc: 0.7354\n",
      "Epoch 11/250\n",
      "52/52 [==============================] - 7s 133ms/step - loss: 0.6114 - acc: 0.6651 - val_loss: 0.5974 - val_acc: 0.6852\n",
      "Epoch 12/250\n",
      "52/52 [==============================] - 7s 136ms/step - loss: 0.6058 - acc: 0.6855 - val_loss: 0.6344 - val_acc: 0.6546\n",
      "Epoch 13/250\n",
      "52/52 [==============================] - 7s 132ms/step - loss: 0.6027 - acc: 0.6650 - val_loss: 0.5682 - val_acc: 0.7187\n",
      "Epoch 14/250\n",
      "52/52 [==============================] - 7s 134ms/step - loss: 0.5695 - acc: 0.7151 - val_loss: 0.6165 - val_acc: 0.6797\n",
      "Epoch 15/250\n",
      "52/52 [==============================] - 7s 135ms/step - loss: 0.5767 - acc: 0.6959 - val_loss: 0.5281 - val_acc: 0.7354\n",
      "Epoch 16/250\n",
      "52/52 [==============================] - 7s 132ms/step - loss: 0.5708 - acc: 0.7027 - val_loss: 0.4907 - val_acc: 0.7577\n",
      "Epoch 17/250\n",
      "52/52 [==============================] - 7s 134ms/step - loss: 0.5205 - acc: 0.7484 - val_loss: 0.4931 - val_acc: 0.7911\n",
      "Epoch 18/250\n",
      "52/52 [==============================] - 7s 134ms/step - loss: 0.5660 - acc: 0.7331 - val_loss: 0.5784 - val_acc: 0.7326\n",
      "Epoch 19/250\n",
      "52/52 [==============================] - 7s 134ms/step - loss: 0.5705 - acc: 0.7248 - val_loss: 0.5059 - val_acc: 0.7855\n",
      "Epoch 20/250\n",
      "52/52 [==============================] - 7s 136ms/step - loss: 0.5389 - acc: 0.7348 - val_loss: 0.6192 - val_acc: 0.7075\n",
      "Epoch 21/250\n",
      "52/52 [==============================] - 7s 134ms/step - loss: 0.5193 - acc: 0.7512 - val_loss: 0.5036 - val_acc: 0.7549\n",
      "Epoch 22/250\n",
      "52/52 [==============================] - 7s 134ms/step - loss: 0.5377 - acc: 0.7268 - val_loss: 0.5476 - val_acc: 0.7716\n",
      "Epoch 23/250\n",
      "52/52 [==============================] - 7s 133ms/step - loss: 0.5067 - acc: 0.7628 - val_loss: 0.5455 - val_acc: 0.7632\n",
      "Epoch 24/250\n",
      "52/52 [==============================] - 7s 136ms/step - loss: 0.5011 - acc: 0.7608 - val_loss: 0.5422 - val_acc: 0.7604\n",
      "Epoch 25/250\n",
      "52/52 [==============================] - 7s 132ms/step - loss: 0.4820 - acc: 0.7588 - val_loss: 0.5152 - val_acc: 0.7772\n",
      "Epoch 26/250\n",
      "52/52 [==============================] - 7s 136ms/step - loss: 0.5043 - acc: 0.7608 - val_loss: 0.5134 - val_acc: 0.7604\n",
      "Epoch 27/250\n",
      "52/52 [==============================] - 7s 136ms/step - loss: 0.4682 - acc: 0.7921 - val_loss: 0.5408 - val_acc: 0.7716\n",
      "Epoch 28/250\n",
      "52/52 [==============================] - 7s 135ms/step - loss: 0.4556 - acc: 0.7825 - val_loss: 0.5484 - val_acc: 0.7577\n",
      "Epoch 29/250\n",
      "52/52 [==============================] - 7s 135ms/step - loss: 0.4206 - acc: 0.8029 - val_loss: 0.5645 - val_acc: 0.7604\n",
      "Epoch 30/250\n",
      "52/52 [==============================] - 7s 136ms/step - loss: 0.4555 - acc: 0.7912 - val_loss: 0.5674 - val_acc: 0.7716\n",
      "Epoch 31/250\n",
      "52/52 [==============================] - 7s 134ms/step - loss: 0.4205 - acc: 0.8069 - val_loss: 0.6381 - val_acc: 0.7549\n",
      "Epoch 32/250\n",
      "52/52 [==============================] - 7s 136ms/step - loss: 0.4081 - acc: 0.8113 - val_loss: 0.6623 - val_acc: 0.7549\n",
      "Epoch 33/250\n",
      "52/52 [==============================] - 7s 138ms/step - loss: 0.3890 - acc: 0.8277 - val_loss: 0.8761 - val_acc: 0.7075\n",
      "Epoch 34/250\n",
      "52/52 [==============================] - 7s 134ms/step - loss: 0.4125 - acc: 0.8189 - val_loss: 0.6388 - val_acc: 0.7632\n",
      "Epoch 35/250\n",
      "52/52 [==============================] - 7s 137ms/step - loss: 0.3608 - acc: 0.8329 - val_loss: 0.5963 - val_acc: 0.7716\n",
      "Epoch 36/250\n",
      "52/52 [==============================] - 7s 132ms/step - loss: 0.3929 - acc: 0.8237 - val_loss: 0.5580 - val_acc: 0.7521\n",
      "Epoch 37/250\n",
      "52/52 [==============================] - 7s 131ms/step - loss: 0.3475 - acc: 0.8405 - val_loss: 0.7123 - val_acc: 0.7326\n",
      "Epoch 38/250\n",
      "52/52 [==============================] - 7s 134ms/step - loss: 0.3770 - acc: 0.8353 - val_loss: 0.7158 - val_acc: 0.7744\n",
      "Epoch 39/250\n",
      "52/52 [==============================] - 7s 136ms/step - loss: 0.3565 - acc: 0.8642 - val_loss: 0.7462 - val_acc: 0.7270\n",
      "Epoch 40/250\n",
      "52/52 [==============================] - 7s 137ms/step - loss: 0.3319 - acc: 0.8566 - val_loss: 0.6561 - val_acc: 0.7632\n",
      "Epoch 41/250\n",
      "52/52 [==============================] - 7s 138ms/step - loss: 0.3370 - acc: 0.8393 - val_loss: 0.6007 - val_acc: 0.7688\n",
      "Epoch 42/250\n",
      "52/52 [==============================] - 7s 136ms/step - loss: 0.3524 - acc: 0.8497 - val_loss: 0.5964 - val_acc: 0.7465\n",
      "Epoch 43/250\n",
      "52/52 [==============================] - 7s 139ms/step - loss: 0.3326 - acc: 0.8586 - val_loss: 0.6584 - val_acc: 0.7521\n",
      "Epoch 44/250\n",
      "52/52 [==============================] - 7s 141ms/step - loss: 0.2812 - acc: 0.8722 - val_loss: 0.7214 - val_acc: 0.7549\n",
      "Epoch 45/250\n",
      "52/52 [==============================] - 7s 135ms/step - loss: 0.2979 - acc: 0.8790 - val_loss: 0.5917 - val_acc: 0.7911\n",
      "Epoch 46/250\n",
      "52/52 [==============================] - 7s 140ms/step - loss: 0.2924 - acc: 0.8698 - val_loss: 0.7118 - val_acc: 0.7549\n",
      "Epoch 47/250\n",
      "52/52 [==============================] - 7s 135ms/step - loss: 0.2925 - acc: 0.9018 - val_loss: 0.6818 - val_acc: 0.7660\n",
      "Epoch 48/250\n",
      "52/52 [==============================] - 7s 135ms/step - loss: 0.2937 - acc: 0.8838 - val_loss: 0.7409 - val_acc: 0.7827\n",
      "Epoch 49/250\n",
      "52/52 [==============================] - 7s 135ms/step - loss: 0.2566 - acc: 0.8882 - val_loss: 0.9200 - val_acc: 0.7744\n",
      "Epoch 50/250\n",
      "52/52 [==============================] - 8s 145ms/step - loss: 0.2773 - acc: 0.8963 - val_loss: 0.9594 - val_acc: 0.7549\n",
      "Epoch 51/250\n",
      "52/52 [==============================] - 7s 133ms/step - loss: 0.2688 - acc: 0.8930 - val_loss: 0.7919 - val_acc: 0.7493\n",
      "Epoch 52/250\n",
      "52/52 [==============================] - 7s 136ms/step - loss: 0.2795 - acc: 0.8810 - val_loss: 0.7184 - val_acc: 0.7493\n",
      "Epoch 53/250\n",
      "52/52 [==============================] - 7s 137ms/step - loss: 0.2440 - acc: 0.9074 - val_loss: 1.0803 - val_acc: 0.7270\n",
      "Epoch 54/250\n",
      "52/52 [==============================] - 7s 132ms/step - loss: 0.2429 - acc: 0.9046 - val_loss: 0.8462 - val_acc: 0.7660\n",
      "Epoch 55/250\n",
      "52/52 [==============================] - 7s 142ms/step - loss: 0.2477 - acc: 0.9043 - val_loss: 1.0146 - val_acc: 0.7270\n",
      "Epoch 56/250\n",
      "52/52 [==============================] - 7s 140ms/step - loss: 0.2322 - acc: 0.9135 - val_loss: 0.8142 - val_acc: 0.7242\n",
      "Epoch 57/250\n",
      "52/52 [==============================] - 7s 137ms/step - loss: 0.2372 - acc: 0.9062 - val_loss: 0.9161 - val_acc: 0.7632\n",
      "Epoch 58/250\n",
      "52/52 [==============================] - 7s 135ms/step - loss: 0.2425 - acc: 0.9006 - val_loss: 0.8730 - val_acc: 0.7437\n",
      "Epoch 59/250\n",
      "52/52 [==============================] - 7s 135ms/step - loss: 0.2214 - acc: 0.9159 - val_loss: 0.9445 - val_acc: 0.7604\n",
      "Epoch 60/250\n",
      "52/52 [==============================] - 7s 134ms/step - loss: 0.2096 - acc: 0.9291 - val_loss: 0.9763 - val_acc: 0.7772\n",
      "Epoch 61/250\n",
      "52/52 [==============================] - 7s 134ms/step - loss: 0.2433 - acc: 0.9123 - val_loss: 0.7537 - val_acc: 0.7660\n",
      "Epoch 62/250\n",
      "52/52 [==============================] - 7s 136ms/step - loss: 0.2078 - acc: 0.9155 - val_loss: 0.9340 - val_acc: 0.7660\n",
      "Epoch 63/250\n",
      "52/52 [==============================] - 7s 135ms/step - loss: 0.2210 - acc: 0.9151 - val_loss: 0.8921 - val_acc: 0.7577\n",
      "Epoch 64/250\n",
      "52/52 [==============================] - 7s 137ms/step - loss: 0.2076 - acc: 0.9251 - val_loss: 0.9028 - val_acc: 0.7577\n",
      "Epoch 65/250\n",
      "52/52 [==============================] - 7s 134ms/step - loss: 0.2230 - acc: 0.9303 - val_loss: 0.8542 - val_acc: 0.7604\n",
      "Epoch 66/250\n",
      "52/52 [==============================] - 7s 140ms/step - loss: 0.1749 - acc: 0.9259 - val_loss: 0.9442 - val_acc: 0.7521\n",
      "Epoch 67/250\n",
      "52/52 [==============================] - 7s 134ms/step - loss: 0.2348 - acc: 0.9055 - val_loss: 0.9364 - val_acc: 0.7577\n",
      "Epoch 68/250\n",
      "52/52 [==============================] - 7s 133ms/step - loss: 0.2001 - acc: 0.9319 - val_loss: 1.1391 - val_acc: 0.7382\n",
      "Epoch 69/250\n",
      "52/52 [==============================] - 7s 135ms/step - loss: 0.1969 - acc: 0.9123 - val_loss: 1.1716 - val_acc: 0.7521\n",
      "Epoch 70/250\n",
      "52/52 [==============================] - 7s 135ms/step - loss: 0.1743 - acc: 0.9371 - val_loss: 1.0775 - val_acc: 0.7660\n",
      "Epoch 71/250\n",
      "52/52 [==============================] - 7s 137ms/step - loss: 0.1647 - acc: 0.9375 - val_loss: 1.1420 - val_acc: 0.7744\n",
      "Epoch 72/250\n",
      "52/52 [==============================] - 7s 137ms/step - loss: 0.1644 - acc: 0.9471 - val_loss: 1.2789 - val_acc: 0.7465\n",
      "Epoch 73/250\n",
      "52/52 [==============================] - 7s 132ms/step - loss: 0.1944 - acc: 0.9263 - val_loss: 1.1920 - val_acc: 0.7437\n",
      "Epoch 74/250\n",
      "52/52 [==============================] - 7s 132ms/step - loss: 0.1523 - acc: 0.9467 - val_loss: 1.3599 - val_acc: 0.7744\n",
      "Epoch 75/250\n",
      "52/52 [==============================] - 7s 133ms/step - loss: 0.1620 - acc: 0.9387 - val_loss: 1.4322 - val_acc: 0.7382\n",
      "Epoch 76/250\n",
      "52/52 [==============================] - 7s 139ms/step - loss: 0.1717 - acc: 0.9387 - val_loss: 1.1413 - val_acc: 0.7465\n",
      "Epoch 77/250\n",
      "52/52 [==============================] - 7s 132ms/step - loss: 0.1817 - acc: 0.9339 - val_loss: 1.2603 - val_acc: 0.7214\n",
      "Epoch 78/250\n",
      "52/52 [==============================] - 7s 138ms/step - loss: 0.1278 - acc: 0.9507 - val_loss: 1.1399 - val_acc: 0.7493\n",
      "Epoch 79/250\n",
      "52/52 [==============================] - 7s 136ms/step - loss: 0.1528 - acc: 0.9447 - val_loss: 1.3918 - val_acc: 0.7409\n",
      "Epoch 80/250\n",
      "52/52 [==============================] - 7s 133ms/step - loss: 0.1800 - acc: 0.9423 - val_loss: 0.9742 - val_acc: 0.7688\n",
      "Epoch 81/250\n",
      "52/52 [==============================] - 7s 138ms/step - loss: 0.1540 - acc: 0.9543 - val_loss: 1.1968 - val_acc: 0.7632\n",
      "Epoch 82/250\n",
      "52/52 [==============================] - 7s 133ms/step - loss: 0.1542 - acc: 0.9411 - val_loss: 1.0629 - val_acc: 0.7855\n",
      "Epoch 83/250\n",
      "52/52 [==============================] - 7s 133ms/step - loss: 0.1988 - acc: 0.9255 - val_loss: 1.0764 - val_acc: 0.7549\n",
      "Epoch 84/250\n",
      "52/52 [==============================] - 7s 136ms/step - loss: 0.1561 - acc: 0.9435 - val_loss: 1.4417 - val_acc: 0.7493\n",
      "Epoch 85/250\n",
      "52/52 [==============================] - 7s 135ms/step - loss: 0.1276 - acc: 0.9495 - val_loss: 1.2318 - val_acc: 0.7827\n",
      "Epoch 86/250\n",
      "52/52 [==============================] - 7s 135ms/step - loss: 0.1126 - acc: 0.9639 - val_loss: 1.5589 - val_acc: 0.7521\n",
      "Epoch 87/250\n",
      "52/52 [==============================] - 7s 136ms/step - loss: 0.1470 - acc: 0.9531 - val_loss: 1.4586 - val_acc: 0.7577\n",
      "Epoch 88/250\n",
      "52/52 [==============================] - 7s 137ms/step - loss: 0.1309 - acc: 0.9411 - val_loss: 1.5190 - val_acc: 0.7772\n",
      "Epoch 89/250\n",
      "52/52 [==============================] - 7s 132ms/step - loss: 0.1406 - acc: 0.9543 - val_loss: 1.2431 - val_acc: 0.7604\n",
      "Epoch 90/250\n",
      "52/52 [==============================] - 7s 134ms/step - loss: 0.1278 - acc: 0.9615 - val_loss: 1.5275 - val_acc: 0.7214\n",
      "Epoch 91/250\n",
      "52/52 [==============================] - 7s 134ms/step - loss: 0.1630 - acc: 0.9411 - val_loss: 1.3703 - val_acc: 0.7465\n",
      "Epoch 92/250\n",
      "52/52 [==============================] - 7s 139ms/step - loss: 0.1604 - acc: 0.9419 - val_loss: 1.0940 - val_acc: 0.7660\n",
      "Epoch 93/250\n",
      "52/52 [==============================] - 7s 137ms/step - loss: 0.1278 - acc: 0.9507 - val_loss: 1.4607 - val_acc: 0.7521\n",
      "Epoch 94/250\n",
      "52/52 [==============================] - 7s 135ms/step - loss: 0.1639 - acc: 0.9459 - val_loss: 1.2040 - val_acc: 0.7604\n",
      "Epoch 95/250\n",
      "52/52 [==============================] - 7s 136ms/step - loss: 0.1326 - acc: 0.9603 - val_loss: 1.5787 - val_acc: 0.7604\n",
      "Epoch 96/250\n",
      "52/52 [==============================] - 7s 138ms/step - loss: 0.1349 - acc: 0.9507 - val_loss: 1.4263 - val_acc: 0.7465\n",
      "Epoch 97/250\n",
      "52/52 [==============================] - 7s 135ms/step - loss: 0.1481 - acc: 0.9603 - val_loss: 1.6663 - val_acc: 0.7716\n",
      "Epoch 98/250\n",
      "52/52 [==============================] - 7s 137ms/step - loss: 0.1333 - acc: 0.9579 - val_loss: 1.7057 - val_acc: 0.7577\n",
      "Epoch 99/250\n",
      "52/52 [==============================] - 7s 133ms/step - loss: 0.1372 - acc: 0.9591 - val_loss: 1.7409 - val_acc: 0.7521\n",
      "Epoch 100/250\n",
      "52/52 [==============================] - 7s 141ms/step - loss: 0.1498 - acc: 0.9615 - val_loss: 0.9999 - val_acc: 0.7549\n",
      "Epoch 101/250\n",
      "52/52 [==============================] - 7s 134ms/step - loss: 0.1525 - acc: 0.9507 - val_loss: 1.3609 - val_acc: 0.7549\n",
      "Epoch 102/250\n",
      "52/52 [==============================] - 7s 139ms/step - loss: 0.1290 - acc: 0.9575 - val_loss: 1.5941 - val_acc: 0.7493\n",
      "Epoch 103/250\n",
      "52/52 [==============================] - 7s 136ms/step - loss: 0.1574 - acc: 0.9507 - val_loss: 1.0829 - val_acc: 0.7660\n",
      "Epoch 104/250\n",
      "52/52 [==============================] - 7s 131ms/step - loss: 0.1693 - acc: 0.9479 - val_loss: 1.2241 - val_acc: 0.7493\n",
      "Epoch 105/250\n",
      "52/52 [==============================] - 7s 133ms/step - loss: 0.1040 - acc: 0.9663 - val_loss: 1.7202 - val_acc: 0.7604\n",
      "Epoch 106/250\n",
      "52/52 [==============================] - 7s 137ms/step - loss: 0.1538 - acc: 0.9527 - val_loss: 1.6336 - val_acc: 0.7465\n",
      "Epoch 107/250\n",
      "52/52 [==============================] - 7s 134ms/step - loss: 0.1461 - acc: 0.9459 - val_loss: 1.4116 - val_acc: 0.7437\n",
      "Epoch 108/250\n",
      "52/52 [==============================] - 8s 145ms/step - loss: 0.1484 - acc: 0.9515 - val_loss: 1.4667 - val_acc: 0.7493\n",
      "Epoch 109/250\n",
      "52/52 [==============================] - 7s 141ms/step - loss: 0.1027 - acc: 0.9575 - val_loss: 1.5797 - val_acc: 0.7521\n",
      "Epoch 110/250\n",
      "52/52 [==============================] - 7s 139ms/step - loss: 0.1510 - acc: 0.9471 - val_loss: 1.6712 - val_acc: 0.7465\n",
      "Epoch 111/250\n",
      "52/52 [==============================] - 7s 135ms/step - loss: 0.1362 - acc: 0.9579 - val_loss: 1.4272 - val_acc: 0.7521\n",
      "Epoch 112/250\n",
      "52/52 [==============================] - 7s 140ms/step - loss: 0.1590 - acc: 0.9507 - val_loss: 1.4951 - val_acc: 0.7577\n",
      "Epoch 113/250\n",
      "52/52 [==============================] - 7s 134ms/step - loss: 0.1218 - acc: 0.9607 - val_loss: 1.6147 - val_acc: 0.7493\n",
      "Epoch 114/250\n",
      "52/52 [==============================] - 7s 133ms/step - loss: 0.1187 - acc: 0.9591 - val_loss: 1.7148 - val_acc: 0.7716\n",
      "Epoch 115/250\n",
      "52/52 [==============================] - 7s 135ms/step - loss: 0.1486 - acc: 0.9519 - val_loss: 1.2607 - val_acc: 0.7382\n",
      "Epoch 116/250\n",
      "52/52 [==============================] - 7s 137ms/step - loss: 0.1489 - acc: 0.9615 - val_loss: 1.2979 - val_acc: 0.7437\n",
      "Epoch 117/250\n",
      "52/52 [==============================] - 7s 132ms/step - loss: 0.1272 - acc: 0.9559 - val_loss: 1.5297 - val_acc: 0.7521\n",
      "Epoch 118/250\n",
      "52/52 [==============================] - 7s 131ms/step - loss: 0.1233 - acc: 0.9615 - val_loss: 1.7047 - val_acc: 0.7465\n",
      "Epoch 119/250\n",
      "52/52 [==============================] - 7s 135ms/step - loss: 0.1451 - acc: 0.9531 - val_loss: 1.6884 - val_acc: 0.7521\n",
      "Epoch 120/250\n",
      "52/52 [==============================] - 7s 139ms/step - loss: 0.1555 - acc: 0.9587 - val_loss: 1.5991 - val_acc: 0.7604\n",
      "Epoch 121/250\n",
      "52/52 [==============================] - 7s 133ms/step - loss: 0.1509 - acc: 0.9495 - val_loss: 1.7483 - val_acc: 0.7382\n",
      "Epoch 122/250\n",
      "52/52 [==============================] - 7s 131ms/step - loss: 0.1134 - acc: 0.9684 - val_loss: 1.5748 - val_acc: 0.7632\n",
      "Epoch 123/250\n",
      "52/52 [==============================] - 7s 131ms/step - loss: 0.1645 - acc: 0.9575 - val_loss: 1.5625 - val_acc: 0.7326\n",
      "Epoch 124/250\n",
      "52/52 [==============================] - 7s 135ms/step - loss: 0.0953 - acc: 0.9688 - val_loss: 1.8012 - val_acc: 0.7772\n",
      "Epoch 125/250\n",
      "52/52 [==============================] - 7s 134ms/step - loss: 0.1488 - acc: 0.9571 - val_loss: 1.7503 - val_acc: 0.7660\n",
      "Epoch 126/250\n",
      "52/52 [==============================] - 7s 136ms/step - loss: 0.1288 - acc: 0.9591 - val_loss: 1.8640 - val_acc: 0.7549\n",
      "Epoch 127/250\n",
      "52/52 [==============================] - 7s 129ms/step - loss: 0.1391 - acc: 0.9635 - val_loss: 1.9504 - val_acc: 0.7744\n",
      "Epoch 128/250\n",
      "52/52 [==============================] - 7s 133ms/step - loss: 0.1110 - acc: 0.9651 - val_loss: 1.8511 - val_acc: 0.7799\n",
      "Epoch 129/250\n",
      "52/52 [==============================] - 7s 137ms/step - loss: 0.1399 - acc: 0.9615 - val_loss: 1.7359 - val_acc: 0.7632\n",
      "Epoch 130/250\n",
      "52/52 [==============================] - 7s 132ms/step - loss: 0.1352 - acc: 0.9611 - val_loss: 2.0085 - val_acc: 0.7660\n",
      "Epoch 131/250\n",
      "52/52 [==============================] - 7s 130ms/step - loss: 0.1405 - acc: 0.9495 - val_loss: 1.4591 - val_acc: 0.7326\n",
      "Epoch 132/250\n",
      "52/52 [==============================] - 7s 136ms/step - loss: 0.1557 - acc: 0.9627 - val_loss: 1.5883 - val_acc: 0.7827\n",
      "Epoch 133/250\n",
      "52/52 [==============================] - 7s 135ms/step - loss: 0.1481 - acc: 0.9567 - val_loss: 1.8194 - val_acc: 0.7772\n",
      "Epoch 134/250\n",
      "52/52 [==============================] - 7s 133ms/step - loss: 0.1105 - acc: 0.9712 - val_loss: 2.4208 - val_acc: 0.7354\n",
      "Epoch 135/250\n",
      "52/52 [==============================] - 7s 137ms/step - loss: 0.1474 - acc: 0.9555 - val_loss: 1.5195 - val_acc: 0.7688\n",
      "Epoch 136/250\n",
      "52/52 [==============================] - 7s 129ms/step - loss: 0.1091 - acc: 0.9627 - val_loss: 1.6943 - val_acc: 0.7716\n",
      "Epoch 137/250\n",
      "52/52 [==============================] - 7s 132ms/step - loss: 0.1756 - acc: 0.9552 - val_loss: 1.6685 - val_acc: 0.7716\n",
      "Epoch 138/250\n",
      "52/52 [==============================] - 7s 133ms/step - loss: 0.1804 - acc: 0.9439 - val_loss: 1.5109 - val_acc: 0.7604\n",
      "Epoch 139/250\n",
      "52/52 [==============================] - 7s 136ms/step - loss: 0.1851 - acc: 0.9423 - val_loss: 1.3784 - val_acc: 0.7744\n",
      "Epoch 140/250\n",
      "52/52 [==============================] - 7s 130ms/step - loss: 0.1352 - acc: 0.9543 - val_loss: 1.7838 - val_acc: 0.7604\n",
      "Epoch 141/250\n",
      "52/52 [==============================] - 7s 133ms/step - loss: 0.2285 - acc: 0.9407 - val_loss: 1.7320 - val_acc: 0.7521\n",
      "Epoch 142/250\n",
      "52/52 [==============================] - 7s 136ms/step - loss: 0.1156 - acc: 0.9567 - val_loss: 1.6917 - val_acc: 0.7799\n",
      "Epoch 143/250\n",
      "52/52 [==============================] - 7s 131ms/step - loss: 0.1226 - acc: 0.9663 - val_loss: 1.6685 - val_acc: 0.7772\n",
      "Epoch 144/250\n",
      "52/52 [==============================] - 7s 136ms/step - loss: 0.0970 - acc: 0.9675 - val_loss: 1.6728 - val_acc: 0.7939\n",
      "Epoch 145/250\n",
      "52/52 [==============================] - 7s 132ms/step - loss: 0.1262 - acc: 0.9591 - val_loss: 1.8154 - val_acc: 0.7409\n",
      "Epoch 146/250\n",
      "52/52 [==============================] - 7s 132ms/step - loss: 0.1495 - acc: 0.9627 - val_loss: 1.9218 - val_acc: 0.7688\n",
      "Epoch 147/250\n",
      "52/52 [==============================] - 7s 130ms/step - loss: 0.2016 - acc: 0.9555 - val_loss: 1.6390 - val_acc: 0.7911\n",
      "Epoch 148/250\n",
      "52/52 [==============================] - 7s 133ms/step - loss: 0.1535 - acc: 0.9507 - val_loss: 1.5585 - val_acc: 0.7326\n",
      "Epoch 149/250\n",
      "52/52 [==============================] - 7s 131ms/step - loss: 0.2039 - acc: 0.9507 - val_loss: 1.3342 - val_acc: 0.7799\n",
      "Epoch 150/250\n",
      "52/52 [==============================] - 7s 131ms/step - loss: 0.1079 - acc: 0.9627 - val_loss: 1.7722 - val_acc: 0.7632\n",
      "Epoch 151/250\n",
      "52/52 [==============================] - 7s 137ms/step - loss: 0.1639 - acc: 0.9499 - val_loss: 1.6516 - val_acc: 0.7855\n",
      "Epoch 152/250\n",
      "52/52 [==============================] - 7s 141ms/step - loss: 0.1829 - acc: 0.9551 - val_loss: 1.6595 - val_acc: 0.7827\n",
      "Epoch 153/250\n",
      "52/52 [==============================] - 7s 132ms/step - loss: 0.1370 - acc: 0.9599 - val_loss: 1.3463 - val_acc: 0.7883\n",
      "Epoch 154/250\n",
      "52/52 [==============================] - 7s 132ms/step - loss: 0.1297 - acc: 0.9712 - val_loss: 1.6281 - val_acc: 0.7883\n",
      "Epoch 155/250\n",
      "52/52 [==============================] - 7s 137ms/step - loss: 0.1973 - acc: 0.9383 - val_loss: 1.6869 - val_acc: 0.7577\n",
      "Epoch 156/250\n",
      "52/52 [==============================] - 7s 131ms/step - loss: 0.1258 - acc: 0.9620 - val_loss: 2.0480 - val_acc: 0.7799\n",
      "Epoch 157/250\n",
      "52/52 [==============================] - 7s 133ms/step - loss: 0.2190 - acc: 0.9519 - val_loss: 1.6837 - val_acc: 0.7632\n",
      "Epoch 158/250\n",
      "52/52 [==============================] - 7s 130ms/step - loss: 0.1307 - acc: 0.9599 - val_loss: 1.3740 - val_acc: 0.7772\n",
      "Epoch 159/250\n",
      "52/52 [==============================] - 7s 134ms/step - loss: 0.1355 - acc: 0.9479 - val_loss: 1.5658 - val_acc: 0.7911\n",
      "Epoch 160/250\n",
      "52/52 [==============================] - 7s 134ms/step - loss: 0.1559 - acc: 0.9579 - val_loss: 1.4872 - val_acc: 0.7772\n",
      "Epoch 161/250\n",
      "52/52 [==============================] - 7s 138ms/step - loss: 0.1354 - acc: 0.9507 - val_loss: 1.6668 - val_acc: 0.7549\n",
      "Epoch 162/250\n",
      "52/52 [==============================] - 7s 136ms/step - loss: 0.1943 - acc: 0.9675 - val_loss: 1.8888 - val_acc: 0.7493\n",
      "Epoch 163/250\n",
      "52/52 [==============================] - 7s 138ms/step - loss: 0.1544 - acc: 0.9559 - val_loss: 1.7720 - val_acc: 0.7660\n",
      "Epoch 164/250\n",
      "52/52 [==============================] - 7s 132ms/step - loss: 0.1527 - acc: 0.9563 - val_loss: 1.5508 - val_acc: 0.7660\n",
      "Epoch 165/250\n",
      "52/52 [==============================] - 7s 134ms/step - loss: 0.0983 - acc: 0.9736 - val_loss: 2.0873 - val_acc: 0.7827\n",
      "Epoch 166/250\n",
      "52/52 [==============================] - 7s 130ms/step - loss: 0.2260 - acc: 0.9459 - val_loss: 1.3974 - val_acc: 0.7716\n",
      "Epoch 167/250\n",
      "52/52 [==============================] - 7s 135ms/step - loss: 0.1923 - acc: 0.9447 - val_loss: 1.1665 - val_acc: 0.7577\n",
      "Epoch 168/250\n",
      "52/52 [==============================] - 7s 131ms/step - loss: 0.1446 - acc: 0.9507 - val_loss: 2.1591 - val_acc: 0.7549\n",
      "Epoch 169/250\n",
      "52/52 [==============================] - 7s 133ms/step - loss: 0.1895 - acc: 0.9519 - val_loss: 1.3390 - val_acc: 0.7772\n",
      "Epoch 170/250\n",
      "52/52 [==============================] - 7s 131ms/step - loss: 0.2087 - acc: 0.9515 - val_loss: 1.9382 - val_acc: 0.7632\n",
      "Epoch 171/250\n",
      "52/52 [==============================] - 7s 135ms/step - loss: 0.1839 - acc: 0.9507 - val_loss: 1.6762 - val_acc: 0.7465\n",
      "Epoch 172/250\n",
      "52/52 [==============================] - 7s 130ms/step - loss: 0.1829 - acc: 0.9459 - val_loss: 1.9543 - val_acc: 0.7744\n",
      "Epoch 173/250\n",
      "52/52 [==============================] - 7s 130ms/step - loss: 0.1356 - acc: 0.9575 - val_loss: 1.6957 - val_acc: 0.7577\n",
      "Epoch 174/250\n",
      "52/52 [==============================] - 7s 144ms/step - loss: 0.1892 - acc: 0.9563 - val_loss: 1.4745 - val_acc: 0.7716\n",
      "Epoch 175/250\n",
      "52/52 [==============================] - 7s 131ms/step - loss: 0.1107 - acc: 0.9639 - val_loss: 1.6566 - val_acc: 0.7521\n",
      "Epoch 176/250\n",
      "52/52 [==============================] - 7s 137ms/step - loss: 0.1366 - acc: 0.9599 - val_loss: 1.8879 - val_acc: 0.7493\n",
      "Epoch 177/250\n",
      "52/52 [==============================] - 7s 134ms/step - loss: 0.2118 - acc: 0.9343 - val_loss: 1.6367 - val_acc: 0.7493\n",
      "Epoch 178/250\n",
      "52/52 [==============================] - 7s 133ms/step - loss: 0.1990 - acc: 0.9495 - val_loss: 1.7963 - val_acc: 0.7660\n",
      "Epoch 179/250\n",
      "52/52 [==============================] - 7s 131ms/step - loss: 0.2013 - acc: 0.9495 - val_loss: 1.6141 - val_acc: 0.7827\n",
      "Epoch 180/250\n",
      "52/52 [==============================] - 7s 131ms/step - loss: 0.2399 - acc: 0.9371 - val_loss: 2.2585 - val_acc: 0.6964\n",
      "Epoch 181/250\n",
      "52/52 [==============================] - 7s 137ms/step - loss: 0.1235 - acc: 0.9675 - val_loss: 1.7155 - val_acc: 0.7716\n",
      "Epoch 182/250\n",
      "52/52 [==============================] - 7s 130ms/step - loss: 0.1972 - acc: 0.9563 - val_loss: 2.0999 - val_acc: 0.7688\n",
      "Epoch 183/250\n",
      "52/52 [==============================] - 7s 132ms/step - loss: 0.2400 - acc: 0.9503 - val_loss: 1.7478 - val_acc: 0.7744\n",
      "Epoch 184/250\n",
      "52/52 [==============================] - 7s 130ms/step - loss: 0.1363 - acc: 0.9591 - val_loss: 2.1081 - val_acc: 0.7744\n",
      "Epoch 185/250\n",
      "52/52 [==============================] - 7s 135ms/step - loss: 0.1596 - acc: 0.9447 - val_loss: 1.5996 - val_acc: 0.7716\n",
      "Epoch 186/250\n",
      "52/52 [==============================] - 7s 131ms/step - loss: 0.1894 - acc: 0.9579 - val_loss: 2.0006 - val_acc: 0.7604\n",
      "Epoch 187/250\n",
      "52/52 [==============================] - 7s 129ms/step - loss: 0.1742 - acc: 0.9579 - val_loss: 1.5387 - val_acc: 0.7521\n",
      "Epoch 188/250\n",
      "52/52 [==============================] - 7s 134ms/step - loss: 0.1753 - acc: 0.9519 - val_loss: 1.4410 - val_acc: 0.7521\n",
      "Epoch 189/250\n",
      "52/52 [==============================] - 7s 134ms/step - loss: 0.2454 - acc: 0.9383 - val_loss: 1.4690 - val_acc: 0.7214\n",
      "Epoch 190/250\n",
      "52/52 [==============================] - 7s 131ms/step - loss: 0.2292 - acc: 0.9339 - val_loss: 1.6889 - val_acc: 0.7688\n",
      "Epoch 191/250\n",
      "52/52 [==============================] - 7s 133ms/step - loss: 0.1958 - acc: 0.9447 - val_loss: 1.4467 - val_acc: 0.7716\n",
      "Epoch 192/250\n",
      "52/52 [==============================] - 7s 131ms/step - loss: 0.2093 - acc: 0.9291 - val_loss: 1.8108 - val_acc: 0.7354\n",
      "Epoch 193/250\n",
      "52/52 [==============================] - 7s 129ms/step - loss: 0.2416 - acc: 0.9383 - val_loss: 1.8122 - val_acc: 0.7716\n",
      "Epoch 194/250\n",
      "52/52 [==============================] - 8s 147ms/step - loss: 0.1872 - acc: 0.9447 - val_loss: 1.8571 - val_acc: 0.7716\n",
      "Epoch 195/250\n",
      "52/52 [==============================] - 7s 134ms/step - loss: 0.1974 - acc: 0.9479 - val_loss: 1.0617 - val_acc: 0.7354\n",
      "Epoch 196/250\n",
      "52/52 [==============================] - 7s 132ms/step - loss: 0.2210 - acc: 0.9375 - val_loss: 1.5203 - val_acc: 0.7465\n",
      "Epoch 197/250\n",
      "52/52 [==============================] - 7s 134ms/step - loss: 0.1727 - acc: 0.9551 - val_loss: 2.0533 - val_acc: 0.7688\n",
      "Epoch 198/250\n",
      "52/52 [==============================] - 7s 132ms/step - loss: 0.2361 - acc: 0.9447 - val_loss: 1.9495 - val_acc: 0.7409\n",
      "Epoch 199/250\n",
      "52/52 [==============================] - 7s 136ms/step - loss: 0.1998 - acc: 0.9495 - val_loss: 2.9361 - val_acc: 0.7409\n",
      "Epoch 200/250\n",
      "52/52 [==============================] - 7s 136ms/step - loss: 0.2352 - acc: 0.9495 - val_loss: 1.6959 - val_acc: 0.7883\n",
      "Epoch 201/250\n",
      "52/52 [==============================] - 7s 129ms/step - loss: 0.1446 - acc: 0.9639 - val_loss: 0.9863 - val_acc: 0.7465\n",
      "Epoch 202/250\n",
      "52/52 [==============================] - 7s 133ms/step - loss: 0.1838 - acc: 0.9543 - val_loss: 1.5207 - val_acc: 0.7521\n",
      "Epoch 203/250\n",
      "52/52 [==============================] - 7s 134ms/step - loss: 0.1884 - acc: 0.9495 - val_loss: 1.8140 - val_acc: 0.7632\n",
      "Epoch 204/250\n",
      "52/52 [==============================] - 7s 130ms/step - loss: 0.1991 - acc: 0.9467 - val_loss: 2.3809 - val_acc: 0.7549\n",
      "Epoch 205/250\n",
      "52/52 [==============================] - 7s 135ms/step - loss: 0.1674 - acc: 0.9620 - val_loss: 1.7163 - val_acc: 0.7493\n",
      "Epoch 206/250\n",
      "52/52 [==============================] - 7s 134ms/step - loss: 0.2269 - acc: 0.9451 - val_loss: 1.9954 - val_acc: 0.7409\n",
      "Epoch 207/250\n",
      "52/52 [==============================] - 7s 132ms/step - loss: 0.2135 - acc: 0.9527 - val_loss: 2.0640 - val_acc: 0.7437\n",
      "Epoch 208/250\n",
      "52/52 [==============================] - 7s 134ms/step - loss: 0.1914 - acc: 0.9599 - val_loss: 1.6891 - val_acc: 0.7883\n",
      "Epoch 209/250\n",
      "52/52 [==============================] - 7s 131ms/step - loss: 0.1454 - acc: 0.9603 - val_loss: 2.0843 - val_acc: 0.7716\n",
      "Epoch 210/250\n",
      "52/52 [==============================] - 7s 133ms/step - loss: 0.1896 - acc: 0.9539 - val_loss: 1.7959 - val_acc: 0.7632\n",
      "Epoch 211/250\n",
      "52/52 [==============================] - 7s 131ms/step - loss: 0.2165 - acc: 0.9447 - val_loss: 1.3918 - val_acc: 0.7577\n",
      "Epoch 212/250\n",
      "52/52 [==============================] - 7s 133ms/step - loss: 0.1911 - acc: 0.9587 - val_loss: 1.2979 - val_acc: 0.7604\n",
      "Epoch 213/250\n",
      "52/52 [==============================] - 7s 132ms/step - loss: 0.2244 - acc: 0.9447 - val_loss: 1.7144 - val_acc: 0.7521\n",
      "Epoch 214/250\n",
      "52/52 [==============================] - 7s 141ms/step - loss: 0.1743 - acc: 0.9499 - val_loss: 1.5644 - val_acc: 0.7382\n",
      "Epoch 215/250\n",
      "52/52 [==============================] - 7s 138ms/step - loss: 0.2121 - acc: 0.9327 - val_loss: 1.6559 - val_acc: 0.7465\n",
      "Epoch 216/250\n",
      "52/52 [==============================] - 7s 135ms/step - loss: 0.2640 - acc: 0.9395 - val_loss: 1.6150 - val_acc: 0.7382\n",
      "Epoch 217/250\n",
      "52/52 [==============================] - 7s 134ms/step - loss: 0.1423 - acc: 0.9539 - val_loss: 1.2990 - val_acc: 0.7744\n",
      "Epoch 218/250\n",
      "52/52 [==============================] - 7s 131ms/step - loss: 0.1748 - acc: 0.9455 - val_loss: 1.3476 - val_acc: 0.7772\n",
      "Epoch 219/250\n",
      "52/52 [==============================] - 7s 135ms/step - loss: 0.2663 - acc: 0.9431 - val_loss: 2.5701 - val_acc: 0.7298\n",
      "Epoch 220/250\n",
      "52/52 [==============================] - 7s 136ms/step - loss: 0.1453 - acc: 0.9627 - val_loss: 2.2410 - val_acc: 0.7799\n",
      "Epoch 221/250\n",
      "52/52 [==============================] - 7s 130ms/step - loss: 0.2506 - acc: 0.9351 - val_loss: 2.6679 - val_acc: 0.7549\n",
      "Epoch 222/250\n",
      "52/52 [==============================] - 7s 132ms/step - loss: 0.2386 - acc: 0.9447 - val_loss: 1.6570 - val_acc: 0.7604\n",
      "Epoch 223/250\n",
      "52/52 [==============================] - 7s 134ms/step - loss: 0.2175 - acc: 0.9427 - val_loss: 1.7258 - val_acc: 0.7799\n",
      "Epoch 224/250\n",
      "52/52 [==============================] - 7s 135ms/step - loss: 0.2868 - acc: 0.9431 - val_loss: 1.0537 - val_acc: 0.7521\n",
      "Epoch 225/250\n",
      "52/52 [==============================] - 7s 144ms/step - loss: 0.2473 - acc: 0.9387 - val_loss: 2.1300 - val_acc: 0.7354\n",
      "Epoch 226/250\n",
      "52/52 [==============================] - 7s 132ms/step - loss: 0.1931 - acc: 0.9483 - val_loss: 1.7571 - val_acc: 0.7716\n",
      "Epoch 227/250\n",
      "52/52 [==============================] - 7s 135ms/step - loss: 0.2619 - acc: 0.9367 - val_loss: 1.6249 - val_acc: 0.7549\n",
      "Epoch 228/250\n",
      "52/52 [==============================] - 7s 133ms/step - loss: 0.2090 - acc: 0.9459 - val_loss: 1.3630 - val_acc: 0.7577\n",
      "Epoch 229/250\n",
      "52/52 [==============================] - 7s 134ms/step - loss: 0.2617 - acc: 0.9207 - val_loss: 1.7904 - val_acc: 0.7632\n",
      "Epoch 230/250\n",
      "52/52 [==============================] - 7s 133ms/step - loss: 0.2748 - acc: 0.9423 - val_loss: 1.9034 - val_acc: 0.7827\n",
      "Epoch 231/250\n",
      "52/52 [==============================] - 7s 135ms/step - loss: 0.1888 - acc: 0.9431 - val_loss: 1.3648 - val_acc: 0.7688\n",
      "Epoch 232/250\n",
      "52/52 [==============================] - 7s 136ms/step - loss: 0.2174 - acc: 0.9435 - val_loss: 1.4818 - val_acc: 0.7772\n",
      "Epoch 233/250\n",
      "52/52 [==============================] - 7s 131ms/step - loss: 0.1688 - acc: 0.9459 - val_loss: 1.1970 - val_acc: 0.7298\n",
      "Epoch 234/250\n",
      "52/52 [==============================] - 7s 135ms/step - loss: 0.2227 - acc: 0.9423 - val_loss: 1.8413 - val_acc: 0.7632\n",
      "Epoch 235/250\n",
      "52/52 [==============================] - 7s 132ms/step - loss: 0.2258 - acc: 0.9471 - val_loss: 1.5444 - val_acc: 0.7688\n",
      "Epoch 236/250\n",
      "52/52 [==============================] - 7s 135ms/step - loss: 0.1887 - acc: 0.9359 - val_loss: 1.6073 - val_acc: 0.7688\n",
      "Epoch 237/250\n",
      "52/52 [==============================] - 7s 133ms/step - loss: 0.2352 - acc: 0.9459 - val_loss: 1.9743 - val_acc: 0.7716\n",
      "Epoch 238/250\n",
      "52/52 [==============================] - 7s 133ms/step - loss: 0.2543 - acc: 0.9339 - val_loss: 1.4955 - val_acc: 0.7855\n",
      "Epoch 239/250\n",
      "52/52 [==============================] - 7s 133ms/step - loss: 0.2508 - acc: 0.9359 - val_loss: 1.2821 - val_acc: 0.7493\n",
      "Epoch 240/250\n",
      "52/52 [==============================] - 7s 133ms/step - loss: 0.2530 - acc: 0.9411 - val_loss: 1.3082 - val_acc: 0.7660\n",
      "Epoch 241/250\n",
      "52/52 [==============================] - 7s 135ms/step - loss: 0.1927 - acc: 0.9483 - val_loss: 1.1066 - val_acc: 0.7911\n",
      "Epoch 242/250\n",
      "52/52 [==============================] - 7s 133ms/step - loss: 0.2454 - acc: 0.9383 - val_loss: 1.4068 - val_acc: 0.7855\n",
      "Epoch 243/250\n",
      "52/52 [==============================] - 7s 131ms/step - loss: 0.1620 - acc: 0.9483 - val_loss: 1.1560 - val_acc: 0.7521\n",
      "Epoch 244/250\n",
      "52/52 [==============================] - 7s 133ms/step - loss: 0.2186 - acc: 0.9351 - val_loss: 1.7349 - val_acc: 0.7827\n",
      "Epoch 245/250\n",
      "52/52 [==============================] - 7s 136ms/step - loss: 0.3547 - acc: 0.9391 - val_loss: 1.5823 - val_acc: 0.7465\n",
      "Epoch 246/250\n",
      "52/52 [==============================] - 7s 132ms/step - loss: 0.3647 - acc: 0.9275 - val_loss: 1.7941 - val_acc: 0.7382\n",
      "Epoch 247/250\n",
      "52/52 [==============================] - 7s 135ms/step - loss: 0.1746 - acc: 0.9507 - val_loss: 1.6564 - val_acc: 0.7632\n",
      "Epoch 248/250\n",
      "52/52 [==============================] - 7s 130ms/step - loss: 0.2139 - acc: 0.9459 - val_loss: 1.6643 - val_acc: 0.7577\n",
      "Epoch 249/250\n",
      "52/52 [==============================] - 7s 134ms/step - loss: 0.2030 - acc: 0.9411 - val_loss: 1.5984 - val_acc: 0.7521\n",
      "Epoch 250/250\n",
      "52/52 [==============================] - 7s 133ms/step - loss: 0.1487 - acc: 0.9531 - val_loss: 1.9874 - val_acc: 0.7772\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=250,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size\n",
    ")\n",
    "\n",
    "model.save_weights('250epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 1s 42ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict_generator(validation_generator, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[116,  91],\n",
       "       [ 83,  69]], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = np.array([0] * 207 + [1] * 152)\n",
    "y_pred = prediction > 0.5\n",
    "\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
