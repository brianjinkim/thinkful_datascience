{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, array_to_img\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense, BatchNormalization\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras import backend as K\n",
    "from keras.optimizers import RMSprop\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allocates GPU memory based on runtime allocations. doesn't releases memory because of potential memory fragmentation\n",
    "# without this option, getting images will not work\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# options\n",
    "img_width, img_height = 100, 100\n",
    "batch_size = 16\n",
    "sample_size = 100\n",
    "epochs = 10\n",
    "\n",
    "# number of classification outputs\n",
    "num_classes=2\n",
    "\n",
    "data_dir = 'data/food'\n",
    "resized_dir = '/resized'\n",
    "original_dir = '/og'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resizes images from directory into new subdirectory\n",
    "def resize(folder, og_dir, new_dir, fileName, width, height):\n",
    "    filePath = os.path.join(folder, fileName)\n",
    "    im = Image.open(filePath)\n",
    "    newIm = im.resize((int(width), int(height)))\n",
    "    directory = re.sub(og_dir, new_dir, folder, count=1) \n",
    "    \n",
    "    # create directory if it doesn't exist\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    # create new file only if it doesn't exist\n",
    "    if not os.path.exists(directory + '/' + fileName):\n",
    "        newIm.save(directory + '/' + fileName)\n",
    "\n",
    "# finds images in directory\n",
    "def bulkResize(imageFolder, original_dir, new_dir, width, height):\n",
    "    imgExts = [\"png\", \"bmp\", \"jpg\"]\n",
    "    for path, dirs, files in os.walk(imageFolder + original_dir):\n",
    "        for fileName in files:\n",
    "            ext = fileName[-3:].lower()\n",
    "            if ext not in imgExts:\n",
    "                continue\n",
    "\n",
    "            resize(path, original_dir, new_dir, fileName, width, height)\n",
    "\n",
    "bulkResize(data_dir, original_dir, resized_dir, img_width, img_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convert image to array and add to df\n",
    "# def loadImgToArray(path, fileName):\n",
    "#     im = Image.open(path+'/'+fileName)\n",
    "#     ar = img_to_array(im)\n",
    "#     ar = ar/255.0\n",
    "#     reshape = ar.reshape(img_width*img_height, 3)\n",
    "#     batch_array = np.concatenate(batch_array, np.array(reshape.shape[0]))\n",
    "# #     batch_label.append()\n",
    "#     remove = re.sub(data_dir+resized_dir, '', path)\n",
    "#     remove = re.sub(r'\\\\', '', remove)\n",
    "#     batch_label = np.concatenate(batch_label, np.array(remove))\n",
    "\n",
    "\n",
    "# # convert to arrays\n",
    "# def bulkConvert(imageFolder):\n",
    "#     imgExts = [\"png\", \"bmp\", \"jpg\"]\n",
    "#     for path, dirs, files in os.walk(imageFolder):\n",
    "#         for fileName in files:\n",
    "#             ext = fileName[-3:].lower()\n",
    "#             if ext not in imgExts:\n",
    "#                 continue\n",
    "\n",
    "#             loadImgToArray(path, fileName)\n",
    "    \n",
    "    \n",
    "# batch_array = np.empty(batch_size)\n",
    "# batch_label = np.empty(batch_size)\n",
    "# bulkConvert(data_dir + resized_dir)\n",
    "\n",
    "# feat_cols = [ 'pixel '+str(i+1) for i in range(img_width*img_height)]\n",
    "# df = pd.DataFrame(batch_array, columns=feat_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(batch_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(horizontal_flip=True)\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "directory = data_dir+resized_dir,\n",
    "target_size = (img_width, img_height),\n",
    "batch_size = batch_size,\n",
    "class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_11 (Conv2D)           (None, 98, 98, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 96, 96, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 147456)            0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 128)               18874496  \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 18,894,658\n",
      "Trainable params: 18,894,402\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 4s 631ms/step - loss: 0.8231 - acc: 0.4896\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 2s 257ms/step - loss: 0.8066 - acc: 0.5704\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 2s 289ms/step - loss: 0.5589 - acc: 0.7292\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 2s 271ms/step - loss: 0.6133 - acc: 0.7232\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 2s 271ms/step - loss: 0.5843 - acc: 0.7075\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 2s 271ms/step - loss: 0.6362 - acc: 0.7020\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 2s 271ms/step - loss: 0.5390 - acc: 0.7126\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 2s 271ms/step - loss: 0.5243 - acc: 0.7394\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 2s 286ms/step - loss: 0.6184 - acc: 0.6562\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 2s 271ms/step - loss: 0.6070 - acc: 0.6433\n",
      "7/7 [==============================] - 0s 62ms/step\n"
     ]
    }
   ],
   "source": [
    "# CNN model with batch normalization\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch= sample_size // batch_size,\n",
    "    epochs=epochs\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "prediction = model.predict_generator(train_generator, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.86027575, 0.13972424],\n",
       "       [0.93687767, 0.0631223 ],\n",
       "       [0.9276148 , 0.07238524],\n",
       "       [0.3128816 , 0.6871184 ],\n",
       "       [0.9335442 , 0.06645579],\n",
       "       [0.73841816, 0.2615819 ],\n",
       "       [0.8585424 , 0.14145768],\n",
       "       [0.9803767 , 0.01962325],\n",
       "       [0.96327025, 0.03672975],\n",
       "       [0.7545611 , 0.24543881],\n",
       "       [0.956774  , 0.04322594],\n",
       "       [0.65553147, 0.3444685 ],\n",
       "       [0.92528325, 0.07471675],\n",
       "       [0.6972712 , 0.30272877],\n",
       "       [0.87768614, 0.12231386],\n",
       "       [0.5677709 , 0.43222913],\n",
       "       [0.965712  , 0.03428799],\n",
       "       [0.9619254 , 0.0380746 ],\n",
       "       [0.9415436 , 0.05845647],\n",
       "       [0.9015077 , 0.09849238],\n",
       "       [0.88028425, 0.11971575],\n",
       "       [0.7736346 , 0.22636537],\n",
       "       [0.6785167 , 0.32148337],\n",
       "       [0.7531976 , 0.24680237],\n",
       "       [0.98974377, 0.01025627],\n",
       "       [0.99382186, 0.00617808],\n",
       "       [0.72819495, 0.271805  ],\n",
       "       [0.78353   , 0.21646994],\n",
       "       [0.9355596 , 0.0644404 ],\n",
       "       [0.4491087 , 0.5508913 ],\n",
       "       [0.97055805, 0.02944191],\n",
       "       [0.9332281 , 0.06677198],\n",
       "       [0.97206455, 0.02793543],\n",
       "       [0.7151242 , 0.28487578],\n",
       "       [0.93787676, 0.0621232 ],\n",
       "       [0.93916196, 0.06083798],\n",
       "       [0.7380321 , 0.2619679 ],\n",
       "       [0.80423546, 0.19576447],\n",
       "       [0.9574148 , 0.04258522],\n",
       "       [0.57906896, 0.42093107],\n",
       "       [0.8317471 , 0.16825289],\n",
       "       [0.9165186 , 0.08348141],\n",
       "       [0.9153373 , 0.08466269],\n",
       "       [0.931859  , 0.06814099],\n",
       "       [0.98310894, 0.01689105],\n",
       "       [0.43871012, 0.56128985],\n",
       "       [0.7689538 , 0.23104617],\n",
       "       [0.89490974, 0.10509025],\n",
       "       [0.9767964 , 0.02320359],\n",
       "       [0.947599  , 0.05240095],\n",
       "       [0.43098745, 0.5690126 ],\n",
       "       [0.94836116, 0.05163885],\n",
       "       [0.88692045, 0.11307958],\n",
       "       [0.84569836, 0.15430161],\n",
       "       [0.8208073 , 0.1791927 ],\n",
       "       [0.97590274, 0.02409723],\n",
       "       [0.9652172 , 0.03478283],\n",
       "       [0.57081056, 0.42918944],\n",
       "       [0.80973965, 0.1902604 ],\n",
       "       [0.89174694, 0.10825314],\n",
       "       [0.89602715, 0.10397281],\n",
       "       [0.9467082 , 0.05329183],\n",
       "       [0.6481378 , 0.35186216],\n",
       "       [0.97071975, 0.02928021],\n",
       "       [0.6889024 , 0.31109762],\n",
       "       [0.8050443 , 0.1949557 ],\n",
       "       [0.98052055, 0.01947944],\n",
       "       [0.7271412 , 0.27285877],\n",
       "       [0.95340323, 0.04659681],\n",
       "       [0.79038817, 0.2096118 ],\n",
       "       [0.9667254 , 0.03327463],\n",
       "       [0.7421563 , 0.25784364],\n",
       "       [0.7951161 , 0.20488384],\n",
       "       [0.8711089 , 0.12889114],\n",
       "       [0.8344862 , 0.16551384],\n",
       "       [0.6237931 , 0.37620687],\n",
       "       [0.92803884, 0.07196118],\n",
       "       [0.97296   , 0.02704004],\n",
       "       [0.9379853 , 0.06201466],\n",
       "       [0.76885307, 0.23114696],\n",
       "       [0.68102485, 0.31897518],\n",
       "       [0.9492018 , 0.05079819],\n",
       "       [0.9377263 , 0.06227373],\n",
       "       [0.9774495 , 0.02255058],\n",
       "       [0.64844096, 0.35155904],\n",
       "       [0.91125244, 0.0887476 ],\n",
       "       [0.6727074 , 0.32729262],\n",
       "       [0.6329045 , 0.36709547],\n",
       "       [0.77934134, 0.22065869],\n",
       "       [0.4978241 , 0.50217587],\n",
       "       [0.95597404, 0.04402602],\n",
       "       [0.9245409 , 0.07545912],\n",
       "       [0.91977787, 0.08022213],\n",
       "       [0.95997214, 0.04002787],\n",
       "       [0.7393021 , 0.26069787],\n",
       "       [0.59932876, 0.40067124],\n",
       "       [0.521444  , 0.47855598],\n",
       "       [0.7381489 , 0.26185107],\n",
       "       [0.9769006 , 0.02309939],\n",
       "       [0.9271932 , 0.07280681]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
